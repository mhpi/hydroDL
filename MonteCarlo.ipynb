{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load rnnSMAP\n"
     ]
    }
   ],
   "source": [
    "import rnnSMAP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "import imp\n",
    "imp.reload(rnnSMAP)\n",
    "rnnSMAP.reload()\n",
    "\n",
    "opt = rnnSMAP.classLSTM.optLSTM(\n",
    "    rootDB=rnnSMAP.kPath['DB_L3_NA'],\n",
    "    rootOut=rnnSMAP.kPath['Out_L3_NA'],\n",
    "    syr=2017, eyr=2017,\n",
    "    var='varLst_Forcing', varC='varConstLst_Noah',\n",
    "    train='CONUSv16f1', dr=0.5, modelOpt='relu',\n",
    "    target='SMAP_AM',gpu=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: overwriting existed optFile. Delete manually.\n",
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/APCP_FORA.csv 0.025990009307861328\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/DLWRF_FORA.csv 0.017647266387939453\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/DSWRF_FORA.csv 0.017976760864257812\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/TMP_2_FORA.csv 0.015628814697265625\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SPFH_2_FORA.csv 0.016108036041259766\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/VGRD_10_FORA.csv 0.015681743621826172\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/UGRD_10_FORA.csv 0.01558995246887207\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SMAP_AM.csv 0.016779184341430664\n",
      "Epoch 1 Loss 0.340 Time 6.94\n",
      "Epoch 2 Loss 0.165 Time 6.73\n",
      "Epoch 3 Loss 0.142 Time 6.70\n",
      "Epoch 4 Loss 0.142 Time 6.72\n",
      "Epoch 5 Loss 0.133 Time 6.70\n",
      "Epoch 6 Loss 0.131 Time 6.74\n",
      "Epoch 7 Loss 0.121 Time 7.11\n",
      "Epoch 8 Loss 0.112 Time 6.80\n",
      "Epoch 9 Loss 0.111 Time 6.80\n",
      "Epoch 10 Loss 0.104 Time 7.12\n",
      "Epoch 11 Loss 0.106 Time 6.90\n",
      "Epoch 12 Loss 0.103 Time 6.85\n",
      "Epoch 13 Loss 0.099 Time 7.69\n",
      "Epoch 14 Loss 0.093 Time 6.95\n",
      "Epoch 15 Loss 0.097 Time 9.18\n",
      "Epoch 16 Loss 0.095 Time 6.88\n",
      "Epoch 17 Loss 0.091 Time 6.88\n",
      "Epoch 18 Loss 0.090 Time 6.94\n",
      "Epoch 19 Loss 0.089 Time 6.90\n",
      "Epoch 20 Loss 0.091 Time 7.21\n",
      "Epoch 21 Loss 0.090 Time 8.47\n",
      "Epoch 22 Loss 0.083 Time 7.68\n",
      "Epoch 23 Loss 0.085 Time 6.77\n",
      "Epoch 24 Loss 0.079 Time 7.42\n",
      "Epoch 25 Loss 0.080 Time 7.31\n",
      "Epoch 26 Loss 0.076 Time 6.99\n",
      "Epoch 27 Loss 0.068 Time 7.36\n",
      "Epoch 28 Loss 0.083 Time 6.95\n",
      "Epoch 29 Loss 0.076 Time 7.53\n",
      "Epoch 30 Loss 0.077 Time 6.97\n",
      "Epoch 31 Loss 0.073 Time 6.83\n",
      "Epoch 32 Loss 0.072 Time 6.84\n",
      "Epoch 33 Loss 0.072 Time 6.72\n",
      "Epoch 34 Loss 0.070 Time 6.74\n",
      "Epoch 35 Loss 0.070 Time 6.72\n",
      "Epoch 36 Loss 0.069 Time 6.82\n",
      "Epoch 37 Loss 0.074 Time 6.75\n",
      "Epoch 38 Loss 0.070 Time 6.86\n",
      "Epoch 39 Loss 0.068 Time 6.73\n",
      "Epoch 40 Loss 0.068 Time 6.76\n",
      "Epoch 41 Loss 0.071 Time 6.77\n",
      "Epoch 42 Loss 0.070 Time 6.76\n",
      "Epoch 43 Loss 0.064 Time 6.75\n",
      "Epoch 44 Loss 0.065 Time 6.73\n",
      "Epoch 45 Loss 0.063 Time 6.91\n",
      "Epoch 46 Loss 0.071 Time 6.74\n",
      "Epoch 47 Loss 0.069 Time 7.03\n",
      "Epoch 48 Loss 0.066 Time 6.75\n",
      "Epoch 49 Loss 0.062 Time 6.76\n",
      "Epoch 50 Loss 0.061 Time 7.08\n",
      "Epoch 51 Loss 0.070 Time 6.78\n",
      "Epoch 52 Loss 0.066 Time 7.16\n",
      "Epoch 53 Loss 0.065 Time 7.22\n",
      "Epoch 54 Loss 0.060 Time 6.99\n",
      "Epoch 55 Loss 0.069 Time 6.88\n",
      "Epoch 56 Loss 0.068 Time 6.98\n",
      "Epoch 57 Loss 0.064 Time 6.87\n",
      "Epoch 58 Loss 0.061 Time 6.79\n",
      "Epoch 59 Loss 0.060 Time 6.90\n",
      "Epoch 60 Loss 0.060 Time 6.81\n",
      "Epoch 61 Loss 0.059 Time 6.81\n",
      "Epoch 62 Loss 0.060 Time 6.82\n",
      "Epoch 63 Loss 0.059 Time 6.80\n",
      "Epoch 64 Loss 0.061 Time 6.88\n",
      "Epoch 65 Loss 0.062 Time 6.83\n",
      "Epoch 66 Loss 0.058 Time 6.83\n",
      "Epoch 67 Loss 0.057 Time 6.87\n",
      "Epoch 68 Loss 0.062 Time 6.78\n",
      "Epoch 69 Loss 0.060 Time 7.24\n",
      "Epoch 70 Loss 0.063 Time 6.99\n",
      "Epoch 71 Loss 0.060 Time 6.82\n",
      "Epoch 72 Loss 0.062 Time 6.87\n",
      "Epoch 73 Loss 0.056 Time 6.89\n",
      "Epoch 74 Loss 0.060 Time 6.90\n",
      "Epoch 75 Loss 0.056 Time 6.85\n",
      "Epoch 76 Loss 0.061 Time 6.88\n",
      "Epoch 77 Loss 0.056 Time 6.86\n",
      "Epoch 78 Loss 0.058 Time 6.90\n",
      "Epoch 79 Loss 0.055 Time 6.87\n",
      "Epoch 80 Loss 0.058 Time 6.88\n",
      "Epoch 81 Loss 0.055 Time 6.90\n",
      "Epoch 82 Loss 0.057 Time 6.99\n",
      "Epoch 83 Loss 0.055 Time 6.85\n",
      "Epoch 84 Loss 0.054 Time 6.86\n",
      "Epoch 85 Loss 0.056 Time 7.20\n",
      "Epoch 86 Loss 0.057 Time 6.91\n",
      "Epoch 87 Loss 0.055 Time 6.87\n",
      "Epoch 88 Loss 0.053 Time 6.89\n",
      "Epoch 89 Loss 0.052 Time 6.87\n",
      "Epoch 90 Loss 0.055 Time 6.88\n",
      "Epoch 91 Loss 0.049 Time 6.87\n",
      "Epoch 92 Loss 0.057 Time 7.01\n",
      "Epoch 93 Loss 0.054 Time 7.08\n",
      "Epoch 94 Loss 0.054 Time 6.90\n",
      "Epoch 95 Loss 0.054 Time 6.89\n",
      "Epoch 96 Loss 0.056 Time 6.87\n",
      "Epoch 97 Loss 0.052 Time 7.12\n",
      "Epoch 98 Loss 0.054 Time 6.89\n",
      "Epoch 99 Loss 0.052 Time 7.16\n",
      "Epoch 100 Loss 0.055 Time 7.00\n",
      "Epoch 101 Loss 0.054 Time 7.19\n",
      "Epoch 102 Loss 0.051 Time 6.84\n",
      "Epoch 103 Loss 0.056 Time 6.85\n",
      "Epoch 104 Loss 0.051 Time 6.83\n",
      "Epoch 105 Loss 0.050 Time 6.84\n",
      "Epoch 106 Loss 0.050 Time 6.84\n",
      "Epoch 107 Loss 0.053 Time 6.84\n",
      "Epoch 108 Loss 0.052 Time 6.88\n",
      "Epoch 109 Loss 0.051 Time 6.86\n",
      "Epoch 110 Loss 0.053 Time 6.85\n",
      "Epoch 111 Loss 0.048 Time 7.06\n",
      "Epoch 112 Loss 0.051 Time 7.10\n",
      "Epoch 113 Loss 0.051 Time 6.90\n",
      "Epoch 114 Loss 0.047 Time 6.85\n",
      "Epoch 115 Loss 0.048 Time 6.85\n",
      "Epoch 116 Loss 0.053 Time 6.98\n",
      "Epoch 117 Loss 0.051 Time 6.95\n",
      "Epoch 118 Loss 0.049 Time 7.68\n",
      "Epoch 119 Loss 0.048 Time 8.98\n",
      "Epoch 120 Loss 0.050 Time 9.67\n",
      "Epoch 121 Loss 0.049 Time 8.30\n",
      "Epoch 122 Loss 0.052 Time 7.85\n",
      "Epoch 123 Loss 0.049 Time 12.56\n",
      "Epoch 124 Loss 0.053 Time 11.10\n",
      "Epoch 125 Loss 0.050 Time 7.23\n",
      "Epoch 126 Loss 0.049 Time 7.13\n",
      "Epoch 127 Loss 0.049 Time 8.51\n",
      "Epoch 128 Loss 0.048 Time 9.11\n",
      "Epoch 129 Loss 0.047 Time 12.20\n",
      "Epoch 130 Loss 0.047 Time 11.70\n",
      "Epoch 131 Loss 0.048 Time 10.89\n",
      "Epoch 132 Loss 0.048 Time 14.64\n",
      "Epoch 133 Loss 0.048 Time 8.77\n",
      "Epoch 134 Loss 0.051 Time 10.54\n",
      "Epoch 135 Loss 0.045 Time 12.36\n",
      "Epoch 136 Loss 0.048 Time 9.12\n",
      "Epoch 137 Loss 0.048 Time 6.72\n",
      "Epoch 138 Loss 0.047 Time 9.86\n",
      "Epoch 139 Loss 0.048 Time 11.47\n",
      "Epoch 140 Loss 0.048 Time 8.74\n",
      "Epoch 141 Loss 0.049 Time 8.20\n",
      "Epoch 142 Loss 0.046 Time 7.67\n",
      "Epoch 143 Loss 0.049 Time 10.22\n",
      "Epoch 144 Loss 0.048 Time 10.24\n",
      "Epoch 145 Loss 0.045 Time 11.80\n",
      "Epoch 146 Loss 0.044 Time 7.30\n",
      "Epoch 147 Loss 0.047 Time 7.01\n",
      "Epoch 148 Loss 0.046 Time 6.93\n",
      "Epoch 149 Loss 0.046 Time 6.81\n",
      "Epoch 150 Loss 0.047 Time 8.29\n",
      "Epoch 151 Loss 0.044 Time 7.66\n",
      "Epoch 152 Loss 0.045 Time 6.77\n",
      "Epoch 153 Loss 0.046 Time 8.12\n",
      "Epoch 154 Loss 0.045 Time 7.19\n",
      "Epoch 155 Loss 0.045 Time 7.54\n",
      "Epoch 156 Loss 0.045 Time 9.28\n",
      "Epoch 157 Loss 0.047 Time 8.07\n",
      "Epoch 158 Loss 0.046 Time 7.44\n",
      "Epoch 159 Loss 0.045 Time 7.41\n",
      "Epoch 160 Loss 0.049 Time 7.30\n",
      "Epoch 161 Loss 0.044 Time 7.34\n",
      "Epoch 162 Loss 0.046 Time 7.00\n",
      "Epoch 163 Loss 0.044 Time 6.96\n",
      "Epoch 164 Loss 0.045 Time 6.92\n",
      "Epoch 165 Loss 0.044 Time 6.93\n",
      "Epoch 166 Loss 0.044 Time 6.95\n",
      "Epoch 167 Loss 0.045 Time 7.08\n",
      "Epoch 168 Loss 0.044 Time 6.95\n",
      "Epoch 169 Loss 0.047 Time 6.92\n",
      "Epoch 170 Loss 0.045 Time 7.19\n",
      "Epoch 171 Loss 0.044 Time 7.24\n",
      "Epoch 172 Loss 0.047 Time 7.34\n",
      "Epoch 173 Loss 0.042 Time 8.83\n",
      "Epoch 174 Loss 0.045 Time 8.13\n",
      "Epoch 175 Loss 0.046 Time 7.75\n",
      "Epoch 176 Loss 0.046 Time 7.13\n",
      "Epoch 177 Loss 0.045 Time 6.93\n",
      "Epoch 178 Loss 0.043 Time 6.94\n",
      "Epoch 179 Loss 0.046 Time 7.79\n",
      "Epoch 180 Loss 0.043 Time 7.12\n",
      "Epoch 181 Loss 0.042 Time 7.17\n",
      "Epoch 182 Loss 0.045 Time 11.97\n",
      "Epoch 183 Loss 0.043 Time 8.93\n",
      "Epoch 184 Loss 0.041 Time 8.20\n",
      "Epoch 185 Loss 0.042 Time 8.24\n",
      "Epoch 186 Loss 0.045 Time 7.07\n",
      "Epoch 187 Loss 0.045 Time 7.62\n",
      "Epoch 188 Loss 0.040 Time 7.33\n",
      "Epoch 189 Loss 0.040 Time 6.80\n",
      "Epoch 190 Loss 0.043 Time 6.86\n",
      "Epoch 191 Loss 0.044 Time 6.85\n",
      "Epoch 192 Loss 0.042 Time 6.80\n",
      "Epoch 193 Loss 0.042 Time 6.84\n",
      "Epoch 194 Loss 0.041 Time 6.81\n",
      "Epoch 195 Loss 0.042 Time 6.79\n",
      "Epoch 196 Loss 0.043 Time 6.79\n",
      "Epoch 197 Loss 0.041 Time 7.32\n",
      "Epoch 198 Loss 0.043 Time 6.90\n",
      "Epoch 199 Loss 0.043 Time 8.42\n",
      "Epoch 200 Loss 0.041 Time 7.07\n",
      "Epoch 201 Loss 0.040 Time 6.71\n",
      "Epoch 202 Loss 0.040 Time 6.87\n",
      "Epoch 203 Loss 0.040 Time 8.17\n",
      "Epoch 204 Loss 0.042 Time 9.47\n",
      "Epoch 205 Loss 0.038 Time 8.72\n",
      "Epoch 206 Loss 0.043 Time 6.81\n",
      "Epoch 207 Loss 0.042 Time 9.31\n",
      "Epoch 208 Loss 0.043 Time 8.76\n",
      "Epoch 209 Loss 0.040 Time 6.91\n",
      "Epoch 210 Loss 0.040 Time 7.01\n",
      "Epoch 211 Loss 0.040 Time 6.89\n",
      "Epoch 212 Loss 0.041 Time 6.80\n",
      "Epoch 213 Loss 0.041 Time 6.81\n",
      "Epoch 214 Loss 0.044 Time 6.94\n",
      "Epoch 215 Loss 0.043 Time 7.03\n",
      "Epoch 216 Loss 0.041 Time 7.40\n",
      "Epoch 217 Loss 0.039 Time 9.61\n",
      "Epoch 218 Loss 0.041 Time 8.24\n",
      "Epoch 219 Loss 0.042 Time 9.30\n",
      "Epoch 220 Loss 0.041 Time 8.82\n",
      "Epoch 221 Loss 0.037 Time 7.19\n",
      "Epoch 222 Loss 0.039 Time 7.17\n",
      "Epoch 223 Loss 0.041 Time 7.71\n",
      "Epoch 224 Loss 0.040 Time 10.14\n",
      "Epoch 225 Loss 0.040 Time 7.39\n",
      "Epoch 226 Loss 0.040 Time 8.30\n",
      "Epoch 227 Loss 0.040 Time 7.45\n",
      "Epoch 228 Loss 0.041 Time 7.31\n",
      "Epoch 229 Loss 0.039 Time 7.76\n",
      "Epoch 230 Loss 0.039 Time 6.84\n",
      "Epoch 231 Loss 0.043 Time 6.80\n",
      "Epoch 232 Loss 0.040 Time 7.96\n",
      "Epoch 233 Loss 0.038 Time 6.98\n",
      "Epoch 234 Loss 0.039 Time 8.07\n",
      "Epoch 235 Loss 0.038 Time 7.63\n",
      "Epoch 236 Loss 0.040 Time 7.09\n",
      "Epoch 237 Loss 0.039 Time 7.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238 Loss 0.040 Time 8.12\n",
      "Epoch 239 Loss 0.037 Time 7.12\n",
      "Epoch 240 Loss 0.038 Time 6.94\n",
      "Epoch 241 Loss 0.038 Time 6.97\n",
      "Epoch 242 Loss 0.040 Time 6.94\n",
      "Epoch 243 Loss 0.039 Time 7.31\n",
      "Epoch 244 Loss 0.039 Time 7.41\n",
      "Epoch 245 Loss 0.041 Time 7.24\n",
      "Epoch 246 Loss 0.039 Time 7.93\n",
      "Epoch 247 Loss 0.039 Time 7.46\n",
      "Epoch 248 Loss 0.038 Time 7.87\n",
      "Epoch 249 Loss 0.040 Time 7.47\n",
      "Epoch 250 Loss 0.038 Time 7.92\n",
      "Epoch 251 Loss 0.037 Time 6.98\n",
      "Epoch 252 Loss 0.036 Time 7.24\n",
      "Epoch 253 Loss 0.036 Time 7.47\n",
      "Epoch 254 Loss 0.038 Time 6.83\n",
      "Epoch 255 Loss 0.037 Time 7.02\n",
      "Epoch 256 Loss 0.037 Time 8.29\n",
      "Epoch 257 Loss 0.038 Time 7.68\n",
      "Epoch 258 Loss 0.039 Time 8.71\n",
      "Epoch 259 Loss 0.039 Time 8.01\n",
      "Epoch 260 Loss 0.038 Time 8.11\n",
      "Epoch 261 Loss 0.038 Time 7.58\n",
      "Epoch 262 Loss 0.038 Time 6.95\n",
      "Epoch 263 Loss 0.038 Time 9.29\n",
      "Epoch 264 Loss 0.039 Time 8.39\n",
      "Epoch 265 Loss 0.038 Time 8.75\n",
      "Epoch 266 Loss 0.038 Time 7.33\n",
      "Epoch 267 Loss 0.039 Time 7.04\n",
      "Epoch 268 Loss 0.036 Time 8.82\n",
      "Epoch 269 Loss 0.041 Time 8.28\n",
      "Epoch 270 Loss 0.036 Time 7.28\n",
      "Epoch 271 Loss 0.036 Time 8.36\n",
      "Epoch 272 Loss 0.037 Time 6.69\n",
      "Epoch 273 Loss 0.037 Time 7.14\n",
      "Epoch 274 Loss 0.035 Time 6.98\n",
      "Epoch 275 Loss 0.037 Time 6.84\n",
      "Epoch 276 Loss 0.038 Time 7.03\n",
      "Epoch 277 Loss 0.036 Time 6.91\n",
      "Epoch 278 Loss 0.037 Time 6.95\n",
      "Epoch 279 Loss 0.035 Time 7.14\n",
      "Epoch 280 Loss 0.037 Time 6.91\n",
      "Epoch 281 Loss 0.036 Time 7.07\n",
      "Epoch 282 Loss 0.036 Time 7.28\n",
      "Epoch 283 Loss 0.036 Time 7.79\n",
      "Epoch 284 Loss 0.036 Time 7.12\n",
      "Epoch 285 Loss 0.037 Time 7.92\n",
      "Epoch 286 Loss 0.037 Time 7.73\n",
      "Epoch 287 Loss 0.038 Time 7.18\n",
      "Epoch 288 Loss 0.037 Time 7.32\n",
      "Epoch 289 Loss 0.037 Time 7.98\n",
      "Epoch 290 Loss 0.037 Time 7.10\n",
      "Epoch 291 Loss 0.035 Time 7.91\n",
      "Epoch 292 Loss 0.036 Time 9.24\n",
      "Epoch 293 Loss 0.036 Time 6.90\n",
      "Epoch 294 Loss 0.037 Time 7.83\n",
      "Epoch 295 Loss 0.036 Time 7.53\n",
      "Epoch 296 Loss 0.034 Time 7.88\n",
      "Epoch 297 Loss 0.037 Time 7.16\n",
      "Epoch 298 Loss 0.036 Time 7.08\n",
      "Epoch 299 Loss 0.035 Time 7.25\n",
      "Epoch 300 Loss 0.036 Time 6.88\n",
      "Epoch 301 Loss 0.036 Time 6.98\n",
      "Epoch 302 Loss 0.036 Time 7.06\n",
      "Epoch 303 Loss 0.035 Time 11.86\n",
      "Epoch 304 Loss 0.035 Time 9.60\n",
      "Epoch 305 Loss 0.035 Time 7.72\n",
      "Epoch 306 Loss 0.035 Time 8.61\n",
      "Epoch 307 Loss 0.036 Time 8.10\n",
      "Epoch 308 Loss 0.037 Time 7.67\n",
      "Epoch 309 Loss 0.034 Time 8.04\n",
      "Epoch 310 Loss 0.033 Time 7.13\n",
      "Epoch 311 Loss 0.035 Time 7.70\n",
      "Epoch 312 Loss 0.037 Time 8.04\n",
      "Epoch 313 Loss 0.037 Time 8.13\n",
      "Epoch 314 Loss 0.034 Time 7.47\n",
      "Epoch 315 Loss 0.035 Time 8.35\n",
      "Epoch 316 Loss 0.034 Time 7.23\n",
      "Epoch 317 Loss 0.034 Time 7.43\n",
      "Epoch 318 Loss 0.034 Time 7.77\n",
      "Epoch 319 Loss 0.034 Time 6.99\n",
      "Epoch 320 Loss 0.036 Time 7.44\n",
      "Epoch 321 Loss 0.035 Time 6.91\n",
      "Epoch 322 Loss 0.035 Time 7.68\n",
      "Epoch 323 Loss 0.036 Time 8.05\n",
      "Epoch 324 Loss 0.036 Time 7.53\n",
      "Epoch 325 Loss 0.034 Time 7.51\n",
      "Epoch 326 Loss 0.036 Time 7.60\n",
      "Epoch 327 Loss 0.035 Time 6.98\n",
      "Epoch 328 Loss 0.034 Time 7.13\n",
      "Epoch 329 Loss 0.035 Time 6.84\n",
      "Epoch 330 Loss 0.035 Time 6.99\n",
      "Epoch 331 Loss 0.035 Time 6.84\n",
      "Epoch 332 Loss 0.035 Time 6.86\n",
      "Epoch 333 Loss 0.035 Time 6.89\n",
      "Epoch 334 Loss 0.034 Time 6.82\n",
      "Epoch 335 Loss 0.034 Time 7.68\n",
      "Epoch 336 Loss 0.034 Time 10.11\n",
      "Epoch 337 Loss 0.033 Time 8.78\n",
      "Epoch 338 Loss 0.034 Time 7.03\n",
      "Epoch 339 Loss 0.034 Time 7.19\n",
      "Epoch 340 Loss 0.035 Time 8.04\n",
      "Epoch 341 Loss 0.034 Time 7.05\n",
      "Epoch 342 Loss 0.034 Time 6.69\n",
      "Epoch 343 Loss 0.035 Time 6.94\n",
      "Epoch 344 Loss 0.032 Time 6.72\n",
      "Epoch 345 Loss 0.035 Time 7.69\n",
      "Epoch 346 Loss 0.035 Time 7.29\n",
      "Epoch 347 Loss 0.034 Time 6.80\n",
      "Epoch 348 Loss 0.035 Time 7.90\n",
      "Epoch 349 Loss 0.035 Time 8.23\n",
      "Epoch 350 Loss 0.034 Time 7.82\n",
      "Epoch 351 Loss 0.034 Time 7.63\n",
      "Epoch 352 Loss 0.035 Time 6.80\n",
      "Epoch 353 Loss 0.031 Time 7.30\n",
      "Epoch 354 Loss 0.033 Time 8.88\n",
      "Epoch 355 Loss 0.034 Time 8.70\n",
      "Epoch 356 Loss 0.035 Time 7.83\n",
      "Epoch 357 Loss 0.034 Time 10.86\n",
      "Epoch 358 Loss 0.033 Time 7.31\n",
      "Epoch 359 Loss 0.036 Time 8.02\n",
      "Epoch 360 Loss 0.033 Time 8.39\n",
      "Epoch 361 Loss 0.033 Time 8.07\n",
      "Epoch 362 Loss 0.033 Time 8.20\n",
      "Epoch 363 Loss 0.033 Time 7.18\n",
      "Epoch 364 Loss 0.032 Time 8.80\n",
      "Epoch 365 Loss 0.033 Time 9.82\n",
      "Epoch 366 Loss 0.032 Time 8.93\n",
      "Epoch 367 Loss 0.032 Time 9.28\n",
      "Epoch 368 Loss 0.034 Time 7.97\n",
      "Epoch 369 Loss 0.034 Time 7.80\n",
      "Epoch 370 Loss 0.033 Time 7.12\n",
      "Epoch 371 Loss 0.033 Time 7.05\n",
      "Epoch 372 Loss 0.034 Time 7.46\n",
      "Epoch 373 Loss 0.032 Time 7.48\n",
      "Epoch 374 Loss 0.029 Time 7.65\n",
      "Epoch 375 Loss 0.033 Time 7.95\n",
      "Epoch 376 Loss 0.034 Time 7.86\n",
      "Epoch 377 Loss 0.033 Time 7.71\n",
      "Epoch 378 Loss 0.032 Time 8.60\n",
      "Epoch 379 Loss 0.032 Time 9.22\n",
      "Epoch 380 Loss 0.033 Time 11.83\n",
      "Epoch 381 Loss 0.033 Time 9.09\n",
      "Epoch 382 Loss 0.031 Time 7.17\n",
      "Epoch 383 Loss 0.031 Time 9.71\n",
      "Epoch 384 Loss 0.033 Time 7.45\n",
      "Epoch 385 Loss 0.033 Time 7.04\n",
      "Epoch 386 Loss 0.032 Time 7.23\n",
      "Epoch 387 Loss 0.032 Time 7.76\n",
      "Epoch 388 Loss 0.033 Time 7.36\n",
      "Epoch 389 Loss 0.032 Time 9.13\n",
      "Epoch 390 Loss 0.033 Time 7.44\n",
      "Epoch 391 Loss 0.032 Time 8.35\n",
      "Epoch 392 Loss 0.033 Time 8.26\n",
      "Epoch 393 Loss 0.031 Time 7.00\n",
      "Epoch 394 Loss 0.033 Time 7.13\n",
      "Epoch 395 Loss 0.034 Time 7.53\n",
      "Epoch 396 Loss 0.034 Time 7.69\n",
      "Epoch 397 Loss 0.032 Time 7.58\n",
      "Epoch 398 Loss 0.031 Time 7.98\n",
      "Epoch 399 Loss 0.031 Time 8.25\n",
      "Epoch 400 Loss 0.032 Time 8.98\n",
      "Epoch 401 Loss 0.032 Time 7.40\n",
      "Epoch 402 Loss 0.029 Time 8.05\n",
      "Epoch 403 Loss 0.030 Time 7.29\n",
      "Epoch 404 Loss 0.031 Time 8.96\n",
      "Epoch 405 Loss 0.033 Time 9.80\n",
      "Epoch 406 Loss 0.032 Time 10.56\n",
      "Epoch 407 Loss 0.033 Time 10.22\n",
      "Epoch 408 Loss 0.032 Time 8.03\n",
      "Epoch 409 Loss 0.031 Time 8.49\n",
      "Epoch 410 Loss 0.032 Time 7.50\n",
      "Epoch 411 Loss 0.032 Time 7.31\n",
      "Epoch 412 Loss 0.030 Time 7.83\n",
      "Epoch 413 Loss 0.030 Time 7.48\n",
      "Epoch 414 Loss 0.033 Time 7.26\n",
      "Epoch 415 Loss 0.031 Time 7.17\n",
      "Epoch 416 Loss 0.032 Time 11.47\n",
      "Epoch 417 Loss 0.031 Time 8.62\n",
      "Epoch 418 Loss 0.031 Time 8.19\n",
      "Epoch 419 Loss 0.032 Time 7.53\n",
      "Epoch 420 Loss 0.031 Time 7.23\n",
      "Epoch 421 Loss 0.032 Time 7.18\n",
      "Epoch 422 Loss 0.032 Time 7.21\n",
      "Epoch 423 Loss 0.030 Time 7.15\n",
      "Epoch 424 Loss 0.031 Time 7.05\n",
      "Epoch 425 Loss 0.031 Time 7.10\n",
      "Epoch 426 Loss 0.032 Time 7.02\n",
      "Epoch 427 Loss 0.031 Time 7.81\n",
      "Epoch 428 Loss 0.030 Time 7.10\n",
      "Epoch 429 Loss 0.032 Time 7.19\n",
      "Epoch 430 Loss 0.031 Time 7.14\n",
      "Epoch 431 Loss 0.031 Time 7.09\n",
      "Epoch 432 Loss 0.030 Time 7.60\n",
      "Epoch 433 Loss 0.031 Time 7.57\n",
      "Epoch 434 Loss 0.031 Time 7.51\n",
      "Epoch 435 Loss 0.031 Time 7.05\n",
      "Epoch 436 Loss 0.032 Time 7.27\n",
      "Epoch 437 Loss 0.031 Time 7.12\n",
      "Epoch 438 Loss 0.031 Time 7.16\n",
      "Epoch 439 Loss 0.030 Time 7.41\n",
      "Epoch 440 Loss 0.031 Time 7.34\n",
      "Epoch 441 Loss 0.031 Time 9.89\n",
      "Epoch 442 Loss 0.030 Time 12.47\n",
      "Epoch 443 Loss 0.030 Time 7.04\n",
      "Epoch 444 Loss 0.030 Time 6.83\n",
      "Epoch 445 Loss 0.031 Time 6.72\n",
      "Epoch 446 Loss 0.031 Time 6.73\n",
      "Epoch 447 Loss 0.031 Time 6.75\n",
      "Epoch 448 Loss 0.031 Time 6.78\n",
      "Epoch 449 Loss 0.032 Time 7.86\n",
      "Epoch 450 Loss 0.030 Time 7.10\n",
      "Epoch 451 Loss 0.030 Time 6.89\n",
      "Epoch 452 Loss 0.031 Time 6.86\n",
      "Epoch 453 Loss 0.030 Time 7.06\n",
      "Epoch 454 Loss 0.029 Time 7.18\n",
      "Epoch 455 Loss 0.030 Time 7.28\n",
      "Epoch 456 Loss 0.029 Time 7.76\n",
      "Epoch 457 Loss 0.031 Time 7.10\n",
      "Epoch 458 Loss 0.030 Time 7.06\n",
      "Epoch 459 Loss 0.029 Time 7.28\n",
      "Epoch 460 Loss 0.030 Time 6.98\n",
      "Epoch 461 Loss 0.033 Time 6.91\n",
      "Epoch 462 Loss 0.031 Time 7.18\n",
      "Epoch 463 Loss 0.030 Time 7.37\n",
      "Epoch 464 Loss 0.030 Time 8.23\n",
      "Epoch 465 Loss 0.031 Time 7.53\n",
      "Epoch 466 Loss 0.031 Time 10.55\n",
      "Epoch 467 Loss 0.029 Time 6.89\n",
      "Epoch 468 Loss 0.030 Time 6.86\n",
      "Epoch 469 Loss 0.031 Time 6.80\n",
      "Epoch 470 Loss 0.030 Time 8.26\n",
      "Epoch 471 Loss 0.029 Time 7.38\n",
      "Epoch 472 Loss 0.029 Time 8.90\n",
      "Epoch 473 Loss 0.030 Time 8.98\n",
      "Epoch 474 Loss 0.030 Time 9.42\n",
      "Epoch 475 Loss 0.030 Time 7.79\n",
      "Epoch 476 Loss 0.030 Time 8.07\n",
      "Epoch 477 Loss 0.028 Time 8.44\n",
      "Epoch 478 Loss 0.030 Time 8.10\n",
      "Epoch 479 Loss 0.028 Time 9.23\n",
      "Epoch 480 Loss 0.028 Time 8.94\n",
      "Epoch 481 Loss 0.030 Time 9.27\n",
      "Epoch 482 Loss 0.029 Time 7.79\n",
      "Epoch 483 Loss 0.031 Time 11.47\n",
      "Epoch 484 Loss 0.028 Time 9.18\n",
      "Epoch 485 Loss 0.028 Time 7.96\n",
      "Epoch 486 Loss 0.029 Time 7.40\n",
      "Epoch 487 Loss 0.030 Time 8.86\n",
      "Epoch 488 Loss 0.029 Time 7.10\n",
      "Epoch 489 Loss 0.028 Time 7.18\n",
      "Epoch 490 Loss 0.028 Time 7.51\n",
      "Epoch 491 Loss 0.030 Time 9.10\n",
      "Epoch 492 Loss 0.028 Time 7.31\n",
      "Epoch 493 Loss 0.028 Time 8.60\n",
      "Epoch 494 Loss 0.030 Time 11.59\n",
      "Epoch 495 Loss 0.028 Time 11.30\n",
      "Epoch 496 Loss 0.030 Time 10.22\n",
      "Epoch 497 Loss 0.029 Time 10.53\n",
      "Epoch 498 Loss 0.030 Time 9.11\n",
      "Epoch 499 Loss 0.031 Time 7.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseAsyncIOLoop._handle_events(14, 1)\n",
      "handle: <Handle BaseAsyncIOLoop._handle_events(14, 1)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 239, in dispatch_shell\n",
      "    sys.stdout.flush()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in flush\n",
      "    if self.pub_thread.thread.is_alive():\n",
      "AttributeError: 'NoneType' object has no attribute 'thread'\n"
     ]
    }
   ],
   "source": [
    "opt['model'] = 'mc'\n",
    "opt['out'] = 'mc'\n",
    "rnnSMAP.funLSTM.trainLSTM(opt)\n",
    "\n",
    "out = opt['out']\n",
    "rootOut = rnnSMAP.kPath['Out_L3_NA']\n",
    "syr = 2015\n",
    "eyr = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 'mc'\n",
    "testName = 'CONUSv16f1'\n",
    "rootDB = rnnSMAP.kPath['DB_L3_NA']\n",
    "rootOut = rnnSMAP.kPath['Out_L3_NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SMAP_AM.csv 0.024343252182006836\n",
      "running test\n",
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/APCP_FORA.csv 0.017850875854492188\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/DLWRF_FORA.csv 0.015573978424072266\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/DSWRF_FORA.csv 0.016811847686767578\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/TMP_2_FORA.csv 0.015455245971679688\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SPFH_2_FORA.csv 0.016010284423828125\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/VGRD_10_FORA.csv 0.015752077102661133\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/UGRD_10_FORA.csv 0.01788020133972168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'rnnSMAP.classLSTM.torchLSTM_cell_mc' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /Users/rajdesai/Desktop/Hydro/output/L3_NA/mc/test_CONUSv16f1_2017_2017_ep500.csv\n",
      "reading /Users/rajdesai/Desktop/Hydro/output/L3_NA/mc/test_CONUSv16f1_2017_2017_ep500.csv\n"
     ]
    }
   ],
   "source": [
    "ds1 = rnnSMAP.classDB.DatasetPost(rootDB=rootDB, subsetName=testName, yrLst=[2017])# define dataset\n",
    "ds1.readData(var='SMAP_AM', field='SMAP')# read target\n",
    "ds1.readPred(rootOut=rootOut, out=out, drMC=0, field='LSTM')# read prediction\n",
    "statErr1 = ds1.statCalError(predField='LSTM', targetField='SMAP')# calculate error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/SMAP_AM.csv 0.023749828338623047\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/SMAP_AM.csv 0.020721912384033203\n",
      "running test\n",
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/APCP_FORA.csv 0.017277956008911133\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/APCP_FORA.csv 0.018038034439086914\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/DLWRF_FORA.csv 0.01746201515197754\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/DLWRF_FORA.csv 0.016767024993896484\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/DSWRF_FORA.csv 0.01590871810913086\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/DSWRF_FORA.csv 0.016913175582885742\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/TMP_2_FORA.csv 0.01892399787902832\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/TMP_2_FORA.csv 0.021756887435913086\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/SPFH_2_FORA.csv 0.017732858657836914\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/SPFH_2_FORA.csv 0.016691923141479492\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/VGRD_10_FORA.csv 0.016103744506835938\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/VGRD_10_FORA.csv 0.016546010971069336\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/UGRD_10_FORA.csv 0.01557612419128418\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/UGRD_10_FORA.csv 0.017986059188842773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'rnnSMAP.classLSTM.torchLSTM_cell_mc' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /Users/rajdesai/Desktop/Hydro/output/L3_NA/mc/test_CONUSv16f1_2015_2016_ep500.csv\n",
      "reading /Users/rajdesai/Desktop/Hydro/output/L3_NA/mc/test_CONUSv16f1_2015_2016_ep500.csv\n"
     ]
    }
   ],
   "source": [
    "ds2 = rnnSMAP.classDB.DatasetPost(rootDB=rootDB, subsetName=testName, yrLst=[2015, 2016])\n",
    "ds2.readData(var='SMAP_AM', field='SMAP')\n",
    "ds2.readPred(rootOut=rootOut, out=out, drMC=0, field='LSTM')\n",
    "statErr2 = ds2.statCalError(predField='LSTM', targetField='SMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "strE = 'RMSE'\n",
    "dataErr = [getattr(statErr1, strE), getattr(statErr2, strE)]\n",
    "fig = rnnSMAP.funPost.plotBox(dataErr, labelC=['train', 'test'], title='Monte Carlo ' + strE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
