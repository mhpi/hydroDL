{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rnnSMAP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load rnnSMAP\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(rnnSMAP)\n",
    "rnnSMAP.reload()\n",
    "\n",
    "opt = rnnSMAP.classLSTM.optLSTM(\n",
    "    rootDB=rnnSMAP.kPath['DB_L3_NA'],\n",
    "    rootOut=rnnSMAP.kPath['Out_L3_NA'],\n",
    "    syr=2017, eyr=2017,\n",
    "    var='varLst_Forcing', varC='varConstLst_Noah',\n",
    "    train='CONUSv16f1', dr=0.5, modelOpt='relu',\n",
    "    target='SMAP_AM',gpu=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: overwriting existed optFile. Delete manually.\n",
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/APCP_FORA.csv 0.0305788516998291\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/DLWRF_FORA.csv 0.030045270919799805\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/DSWRF_FORA.csv 0.02330803871154785\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/TMP_2_FORA.csv 0.022517919540405273\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SPFH_2_FORA.csv 0.029582977294921875\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/VGRD_10_FORA.csv 0.033631086349487305\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/UGRD_10_FORA.csv 0.03145027160644531\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SMAP_AM.csv 0.02871561050415039\n",
      "Epoch 1 Loss 0.781 time 0.66\n",
      "Epoch 2 Loss 0.369 time 0.55\n",
      "Epoch 3 Loss 0.195 time 0.51\n",
      "Epoch 4 Loss 0.155 time 0.53\n",
      "Epoch 5 Loss 0.140 time 0.61\n",
      "Epoch 6 Loss 0.137 time 0.56\n",
      "Epoch 7 Loss 0.124 time 0.56\n",
      "Epoch 8 Loss 0.121 time 0.56\n",
      "Epoch 9 Loss 0.119 time 0.57\n",
      "Epoch 10 Loss 0.108 time 0.61\n",
      "Epoch 11 Loss 0.111 time 0.51\n",
      "Epoch 12 Loss 0.112 time 0.66\n",
      "Epoch 13 Loss 0.103 time 0.55\n",
      "Epoch 14 Loss 0.105 time 0.55\n",
      "Epoch 15 Loss 0.099 time 0.54\n",
      "Epoch 16 Loss 0.100 time 0.51\n",
      "Epoch 17 Loss 0.098 time 0.58\n",
      "Epoch 18 Loss 0.098 time 0.59\n",
      "Epoch 19 Loss 0.096 time 0.56\n",
      "Epoch 20 Loss 0.096 time 0.51\n",
      "Epoch 21 Loss 0.097 time 0.50\n",
      "Epoch 22 Loss 0.096 time 0.51\n",
      "Epoch 23 Loss 0.094 time 0.49\n",
      "Epoch 24 Loss 0.095 time 0.64\n",
      "Epoch 25 Loss 0.093 time 0.86\n",
      "Epoch 26 Loss 0.092 time 0.63\n",
      "Epoch 27 Loss 0.091 time 0.54\n",
      "Epoch 28 Loss 0.092 time 0.53\n",
      "Epoch 29 Loss 0.086 time 0.45\n",
      "Epoch 30 Loss 0.090 time 0.41\n",
      "Epoch 31 Loss 0.088 time 0.61\n",
      "Epoch 32 Loss 0.085 time 0.62\n",
      "Epoch 33 Loss 0.086 time 0.47\n",
      "Epoch 34 Loss 0.083 time 0.74\n",
      "Epoch 35 Loss 0.082 time 0.62\n",
      "Epoch 36 Loss 0.085 time 0.64\n",
      "Epoch 37 Loss 0.080 time 0.53\n",
      "Epoch 38 Loss 0.085 time 0.57\n",
      "Epoch 39 Loss 0.086 time 0.52\n",
      "Epoch 40 Loss 0.085 time 0.48\n",
      "Epoch 41 Loss 0.078 time 0.50\n",
      "Epoch 42 Loss 0.083 time 0.48\n",
      "Epoch 43 Loss 0.082 time 0.50\n",
      "Epoch 44 Loss 0.084 time 0.48\n",
      "Epoch 45 Loss 0.079 time 0.49\n",
      "Epoch 46 Loss 0.084 time 0.45\n",
      "Epoch 47 Loss 0.081 time 0.50\n",
      "Epoch 48 Loss 0.081 time 0.41\n",
      "Epoch 49 Loss 0.080 time 0.44\n",
      "Epoch 50 Loss 0.081 time 0.42\n",
      "Epoch 51 Loss 0.082 time 0.55\n",
      "Epoch 52 Loss 0.080 time 0.43\n",
      "Epoch 53 Loss 0.081 time 0.43\n",
      "Epoch 54 Loss 0.079 time 0.47\n",
      "Epoch 55 Loss 0.082 time 0.45\n",
      "Epoch 56 Loss 0.081 time 0.46\n",
      "Epoch 57 Loss 0.079 time 0.45\n",
      "Epoch 58 Loss 0.079 time 0.42\n",
      "Epoch 59 Loss 0.075 time 0.48\n",
      "Epoch 60 Loss 0.075 time 0.65\n",
      "Epoch 61 Loss 0.080 time 0.51\n",
      "Epoch 62 Loss 0.077 time 0.57\n",
      "Epoch 63 Loss 0.076 time 0.50\n",
      "Epoch 64 Loss 0.079 time 0.53\n",
      "Epoch 65 Loss 0.080 time 0.48\n",
      "Epoch 66 Loss 0.078 time 0.54\n",
      "Epoch 67 Loss 0.081 time 0.51\n",
      "Epoch 68 Loss 0.079 time 0.52\n",
      "Epoch 69 Loss 0.080 time 0.45\n",
      "Epoch 70 Loss 0.077 time 0.44\n",
      "Epoch 71 Loss 0.077 time 0.43\n",
      "Epoch 72 Loss 0.074 time 0.54\n",
      "Epoch 73 Loss 0.077 time 0.49\n",
      "Epoch 74 Loss 0.081 time 0.48\n",
      "Epoch 75 Loss 0.075 time 0.48\n",
      "Epoch 76 Loss 0.080 time 0.43\n",
      "Epoch 77 Loss 0.075 time 0.43\n",
      "Epoch 78 Loss 0.077 time 0.60\n",
      "Epoch 79 Loss 0.079 time 0.57\n",
      "Epoch 80 Loss 0.074 time 0.48\n",
      "Epoch 81 Loss 0.080 time 0.67\n",
      "Epoch 82 Loss 0.074 time 0.77\n",
      "Epoch 83 Loss 0.073 time 0.48\n",
      "Epoch 84 Loss 0.077 time 0.51\n",
      "Epoch 85 Loss 0.074 time 0.51\n",
      "Epoch 86 Loss 0.076 time 0.52\n",
      "Epoch 87 Loss 0.071 time 0.46\n",
      "Epoch 88 Loss 0.071 time 0.52\n",
      "Epoch 89 Loss 0.081 time 0.52\n",
      "Epoch 90 Loss 0.073 time 0.54\n",
      "Epoch 91 Loss 0.077 time 0.49\n",
      "Epoch 92 Loss 0.074 time 0.43\n",
      "Epoch 93 Loss 0.072 time 0.53\n",
      "Epoch 94 Loss 0.072 time 0.48\n",
      "Epoch 95 Loss 0.073 time 0.41\n",
      "Epoch 96 Loss 0.073 time 0.49\n",
      "Epoch 97 Loss 0.072 time 0.48\n",
      "Epoch 98 Loss 0.071 time 0.44\n",
      "Epoch 99 Loss 0.075 time 0.52\n",
      "Epoch 100 Loss 0.075 time 0.54\n",
      "Epoch 101 Loss 0.074 time 0.51\n",
      "Epoch 102 Loss 0.072 time 0.54\n",
      "Epoch 103 Loss 0.072 time 0.45\n",
      "Epoch 104 Loss 0.071 time 0.47\n",
      "Epoch 105 Loss 0.072 time 0.43\n",
      "Epoch 106 Loss 0.072 time 0.49\n",
      "Epoch 107 Loss 0.073 time 0.47\n",
      "Epoch 108 Loss 0.072 time 0.43\n",
      "Epoch 109 Loss 0.073 time 0.55\n",
      "Epoch 110 Loss 0.073 time 0.45\n",
      "Epoch 111 Loss 0.080 time 0.41\n",
      "Epoch 112 Loss 0.074 time 0.42\n",
      "Epoch 113 Loss 0.070 time 0.43\n",
      "Epoch 114 Loss 0.073 time 0.40\n",
      "Epoch 115 Loss 0.074 time 0.42\n",
      "Epoch 116 Loss 0.074 time 0.44\n",
      "Epoch 117 Loss 0.073 time 0.53\n",
      "Epoch 118 Loss 0.068 time 0.57\n",
      "Epoch 119 Loss 0.072 time 0.44\n",
      "Epoch 120 Loss 0.072 time 0.43\n",
      "Epoch 121 Loss 0.076 time 0.43\n",
      "Epoch 122 Loss 0.069 time 0.42\n",
      "Epoch 123 Loss 0.073 time 0.45\n",
      "Epoch 124 Loss 0.076 time 0.42\n",
      "Epoch 125 Loss 0.072 time 0.51\n",
      "Epoch 126 Loss 0.072 time 0.50\n",
      "Epoch 127 Loss 0.071 time 0.42\n",
      "Epoch 128 Loss 0.070 time 0.50\n",
      "Epoch 129 Loss 0.070 time 0.44\n",
      "Epoch 130 Loss 0.070 time 0.41\n",
      "Epoch 131 Loss 0.068 time 0.41\n",
      "Epoch 132 Loss 0.070 time 0.43\n",
      "Epoch 133 Loss 0.072 time 0.45\n",
      "Epoch 134 Loss 0.066 time 0.47\n",
      "Epoch 135 Loss 0.066 time 0.44\n",
      "Epoch 136 Loss 0.068 time 0.44\n",
      "Epoch 137 Loss 0.073 time 0.43\n",
      "Epoch 138 Loss 0.067 time 0.45\n",
      "Epoch 139 Loss 0.068 time 0.44\n",
      "Epoch 140 Loss 0.069 time 0.44\n",
      "Epoch 141 Loss 0.073 time 0.48\n",
      "Epoch 142 Loss 0.073 time 0.45\n",
      "Epoch 143 Loss 0.072 time 0.47\n",
      "Epoch 144 Loss 0.069 time 0.45\n",
      "Epoch 145 Loss 0.069 time 0.44\n",
      "Epoch 146 Loss 0.069 time 0.46\n",
      "Epoch 147 Loss 0.069 time 0.37\n",
      "Epoch 148 Loss 0.069 time 0.42\n",
      "Epoch 149 Loss 0.067 time 0.46\n",
      "Epoch 150 Loss 0.071 time 0.51\n",
      "Epoch 151 Loss 0.065 time 0.40\n",
      "Epoch 152 Loss 0.070 time 0.40\n",
      "Epoch 153 Loss 0.066 time 0.41\n",
      "Epoch 154 Loss 0.070 time 0.39\n",
      "Epoch 155 Loss 0.070 time 0.48\n",
      "Epoch 156 Loss 0.069 time 0.41\n",
      "Epoch 157 Loss 0.068 time 0.48\n",
      "Epoch 158 Loss 0.067 time 0.48\n",
      "Epoch 159 Loss 0.069 time 0.50\n",
      "Epoch 160 Loss 0.066 time 0.40\n",
      "Epoch 161 Loss 0.069 time 0.45\n",
      "Epoch 162 Loss 0.071 time 0.50\n",
      "Epoch 163 Loss 0.072 time 0.47\n",
      "Epoch 164 Loss 0.065 time 0.47\n",
      "Epoch 165 Loss 0.072 time 0.63\n",
      "Epoch 166 Loss 0.071 time 0.80\n",
      "Epoch 167 Loss 0.071 time 0.57\n",
      "Epoch 168 Loss 0.071 time 0.54\n",
      "Epoch 169 Loss 0.069 time 0.60\n",
      "Epoch 170 Loss 0.070 time 0.55\n",
      "Epoch 171 Loss 0.067 time 0.54\n",
      "Epoch 172 Loss 0.066 time 0.51\n",
      "Epoch 173 Loss 0.067 time 0.55\n",
      "Epoch 174 Loss 0.064 time 0.53\n",
      "Epoch 175 Loss 0.070 time 0.58\n",
      "Epoch 176 Loss 0.070 time 0.54\n",
      "Epoch 177 Loss 0.066 time 0.49\n",
      "Epoch 178 Loss 0.067 time 0.54\n",
      "Epoch 179 Loss 0.066 time 0.57\n",
      "Epoch 180 Loss 0.070 time 0.54\n",
      "Epoch 181 Loss 0.063 time 0.56\n",
      "Epoch 182 Loss 0.071 time 0.54\n",
      "Epoch 183 Loss 0.072 time 0.49\n",
      "Epoch 184 Loss 0.072 time 0.56\n",
      "Epoch 185 Loss 0.068 time 0.46\n",
      "Epoch 186 Loss 0.069 time 0.51\n",
      "Epoch 187 Loss 0.062 time 0.46\n",
      "Epoch 188 Loss 0.064 time 0.42\n",
      "Epoch 189 Loss 0.066 time 0.44\n",
      "Epoch 190 Loss 0.067 time 0.50\n",
      "Epoch 191 Loss 0.072 time 0.54\n",
      "Epoch 192 Loss 0.067 time 0.46\n",
      "Epoch 193 Loss 0.069 time 0.41\n",
      "Epoch 194 Loss 0.068 time 0.44\n",
      "Epoch 195 Loss 0.064 time 0.39\n",
      "Epoch 196 Loss 0.067 time 0.49\n",
      "Epoch 197 Loss 0.066 time 0.90\n",
      "Epoch 198 Loss 0.065 time 0.42\n",
      "Epoch 199 Loss 0.069 time 0.41\n",
      "Epoch 200 Loss 0.061 time 0.51\n",
      "Epoch 201 Loss 0.064 time 0.53\n",
      "Epoch 202 Loss 0.065 time 0.48\n",
      "Epoch 203 Loss 0.069 time 0.45\n",
      "Epoch 204 Loss 0.067 time 0.47\n",
      "Epoch 205 Loss 0.064 time 0.51\n",
      "Epoch 206 Loss 0.065 time 0.53\n",
      "Epoch 207 Loss 0.066 time 0.76\n",
      "Epoch 208 Loss 0.068 time 0.55\n",
      "Epoch 209 Loss 0.065 time 0.63\n",
      "Epoch 210 Loss 0.067 time 0.42\n",
      "Epoch 211 Loss 0.064 time 0.52\n",
      "Epoch 212 Loss 0.069 time 0.43\n",
      "Epoch 213 Loss 0.067 time 0.50\n",
      "Epoch 214 Loss 0.065 time 0.73\n",
      "Epoch 215 Loss 0.065 time 0.65\n",
      "Epoch 216 Loss 0.064 time 0.66\n",
      "Epoch 217 Loss 0.065 time 0.46\n",
      "Epoch 218 Loss 0.070 time 0.67\n",
      "Epoch 219 Loss 0.065 time 0.54\n",
      "Epoch 220 Loss 0.065 time 0.57\n",
      "Epoch 221 Loss 0.071 time 0.67\n",
      "Epoch 222 Loss 0.068 time 0.42\n",
      "Epoch 223 Loss 0.066 time 0.57\n",
      "Epoch 224 Loss 0.065 time 0.58\n",
      "Epoch 225 Loss 0.070 time 0.44\n",
      "Epoch 226 Loss 0.065 time 0.57\n",
      "Epoch 227 Loss 0.067 time 0.62\n",
      "Epoch 228 Loss 0.068 time 0.55\n",
      "Epoch 229 Loss 0.065 time 0.50\n",
      "Epoch 230 Loss 0.068 time 0.55\n",
      "Epoch 231 Loss 0.060 time 0.54\n",
      "Epoch 232 Loss 0.063 time 0.53\n",
      "Epoch 233 Loss 0.065 time 0.72\n",
      "Epoch 234 Loss 0.069 time 0.64\n",
      "Epoch 235 Loss 0.064 time 0.49\n",
      "Epoch 236 Loss 0.062 time 0.73\n",
      "Epoch 237 Loss 0.062 time 0.74\n",
      "Epoch 238 Loss 0.069 time 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239 Loss 0.062 time 0.54\n",
      "Epoch 240 Loss 0.066 time 0.60\n",
      "Epoch 241 Loss 0.064 time 0.46\n",
      "Epoch 242 Loss 0.071 time 0.60\n",
      "Epoch 243 Loss 0.062 time 0.58\n",
      "Epoch 244 Loss 0.067 time 0.41\n",
      "Epoch 245 Loss 0.064 time 0.49\n",
      "Epoch 246 Loss 0.061 time 0.41\n",
      "Epoch 247 Loss 0.065 time 0.43\n",
      "Epoch 248 Loss 0.067 time 0.54\n",
      "Epoch 249 Loss 0.061 time 0.52\n",
      "Epoch 250 Loss 0.064 time 0.58\n",
      "Epoch 251 Loss 0.065 time 0.71\n",
      "Epoch 252 Loss 0.062 time 0.56\n",
      "Epoch 253 Loss 0.066 time 0.56\n",
      "Epoch 254 Loss 0.069 time 0.65\n",
      "Epoch 255 Loss 0.060 time 0.80\n",
      "Epoch 256 Loss 0.061 time 0.56\n",
      "Epoch 257 Loss 0.064 time 0.62\n",
      "Epoch 258 Loss 0.063 time 0.51\n",
      "Epoch 259 Loss 0.068 time 0.47\n",
      "Epoch 260 Loss 0.063 time 0.76\n",
      "Epoch 261 Loss 0.063 time 0.68\n",
      "Epoch 262 Loss 0.062 time 0.93\n",
      "Epoch 263 Loss 0.066 time 0.63\n",
      "Epoch 264 Loss 0.063 time 0.66\n",
      "Epoch 265 Loss 0.061 time 0.66\n",
      "Epoch 266 Loss 0.062 time 0.54\n",
      "Epoch 267 Loss 0.061 time 0.52\n",
      "Epoch 268 Loss 0.062 time 0.43\n",
      "Epoch 269 Loss 0.065 time 0.51\n",
      "Epoch 270 Loss 0.063 time 0.60\n",
      "Epoch 271 Loss 0.065 time 0.41\n",
      "Epoch 272 Loss 0.062 time 0.50\n",
      "Epoch 273 Loss 0.062 time 0.47\n",
      "Epoch 274 Loss 0.066 time 0.53\n",
      "Epoch 275 Loss 0.064 time 0.58\n",
      "Epoch 276 Loss 0.064 time 0.73\n",
      "Epoch 277 Loss 0.062 time 0.73\n",
      "Epoch 278 Loss 0.064 time 0.56\n",
      "Epoch 279 Loss 0.066 time 0.51\n",
      "Epoch 280 Loss 0.061 time 0.56\n",
      "Epoch 281 Loss 0.064 time 0.52\n",
      "Epoch 282 Loss 0.063 time 0.51\n",
      "Epoch 283 Loss 0.063 time 0.52\n",
      "Epoch 284 Loss 0.062 time 0.52\n",
      "Epoch 285 Loss 0.066 time 0.57\n",
      "Epoch 286 Loss 0.064 time 0.62\n",
      "Epoch 287 Loss 0.060 time 0.59\n",
      "Epoch 288 Loss 0.066 time 0.56\n",
      "Epoch 289 Loss 0.062 time 0.55\n",
      "Epoch 290 Loss 0.066 time 0.55\n",
      "Epoch 291 Loss 0.062 time 0.68\n",
      "Epoch 292 Loss 0.060 time 0.67\n",
      "Epoch 293 Loss 0.063 time 0.48\n",
      "Epoch 294 Loss 0.062 time 0.62\n",
      "Epoch 295 Loss 0.061 time 0.56\n",
      "Epoch 296 Loss 0.065 time 0.87\n",
      "Epoch 297 Loss 0.064 time 0.76\n",
      "Epoch 298 Loss 0.059 time 0.57\n",
      "Epoch 299 Loss 0.065 time 0.57\n",
      "Epoch 300 Loss 0.063 time 0.54\n",
      "Epoch 301 Loss 0.063 time 0.60\n",
      "Epoch 302 Loss 0.065 time 0.76\n",
      "Epoch 303 Loss 0.063 time 0.77\n",
      "Epoch 304 Loss 0.064 time 0.66\n",
      "Epoch 305 Loss 0.061 time 0.61\n",
      "Epoch 306 Loss 0.066 time 0.62\n",
      "Epoch 307 Loss 0.059 time 0.59\n",
      "Epoch 308 Loss 0.064 time 0.62\n",
      "Epoch 309 Loss 0.064 time 0.56\n",
      "Epoch 310 Loss 0.063 time 0.72\n",
      "Epoch 311 Loss 0.062 time 0.76\n",
      "Epoch 312 Loss 0.060 time 0.99\n",
      "Epoch 313 Loss 0.061 time 0.78\n",
      "Epoch 314 Loss 0.065 time 0.71\n",
      "Epoch 315 Loss 0.062 time 0.55\n",
      "Epoch 316 Loss 0.064 time 0.57\n",
      "Epoch 317 Loss 0.062 time 0.48\n",
      "Epoch 318 Loss 0.059 time 0.53\n",
      "Epoch 319 Loss 0.059 time 0.63\n",
      "Epoch 320 Loss 0.064 time 0.78\n",
      "Epoch 321 Loss 0.064 time 0.59\n",
      "Epoch 322 Loss 0.064 time 0.59\n",
      "Epoch 323 Loss 0.060 time 0.53\n",
      "Epoch 324 Loss 0.057 time 0.74\n",
      "Epoch 325 Loss 0.065 time 0.76\n",
      "Epoch 326 Loss 0.063 time 0.55\n",
      "Epoch 327 Loss 0.064 time 0.56\n",
      "Epoch 328 Loss 0.064 time 0.41\n",
      "Epoch 329 Loss 0.060 time 0.52\n",
      "Epoch 330 Loss 0.061 time 0.54\n",
      "Epoch 331 Loss 0.063 time 0.66\n",
      "Epoch 332 Loss 0.061 time 0.73\n",
      "Epoch 333 Loss 0.059 time 0.58\n",
      "Epoch 334 Loss 0.056 time 0.58\n",
      "Epoch 335 Loss 0.060 time 0.53\n",
      "Epoch 336 Loss 0.055 time 0.52\n",
      "Epoch 337 Loss 0.062 time 0.53\n",
      "Epoch 338 Loss 0.056 time 0.53\n",
      "Epoch 339 Loss 0.062 time 0.49\n",
      "Epoch 340 Loss 0.059 time 0.64\n",
      "Epoch 341 Loss 0.062 time 1.08\n",
      "Epoch 342 Loss 0.058 time 0.63\n",
      "Epoch 343 Loss 0.061 time 0.59\n",
      "Epoch 344 Loss 0.059 time 0.47\n",
      "Epoch 345 Loss 0.062 time 0.50\n",
      "Epoch 346 Loss 0.059 time 0.46\n",
      "Epoch 347 Loss 0.063 time 0.42\n",
      "Epoch 348 Loss 0.063 time 0.46\n",
      "Epoch 349 Loss 0.059 time 0.45\n",
      "Epoch 350 Loss 0.058 time 0.56\n",
      "Epoch 351 Loss 0.060 time 0.43\n",
      "Epoch 352 Loss 0.063 time 0.45\n",
      "Epoch 353 Loss 0.063 time 0.41\n",
      "Epoch 354 Loss 0.060 time 0.44\n",
      "Epoch 355 Loss 0.059 time 0.50\n",
      "Epoch 356 Loss 0.059 time 0.44\n",
      "Epoch 357 Loss 0.058 time 0.56\n",
      "Epoch 358 Loss 0.056 time 0.48\n",
      "Epoch 359 Loss 0.058 time 0.42\n",
      "Epoch 360 Loss 0.056 time 0.45\n",
      "Epoch 361 Loss 0.064 time 0.39\n",
      "Epoch 362 Loss 0.062 time 0.46\n",
      "Epoch 363 Loss 0.061 time 0.45\n",
      "Epoch 364 Loss 0.061 time 0.48\n",
      "Epoch 365 Loss 0.062 time 0.46\n",
      "Epoch 366 Loss 0.060 time 0.59\n",
      "Epoch 367 Loss 0.061 time 0.51\n",
      "Epoch 368 Loss 0.063 time 0.49\n",
      "Epoch 369 Loss 0.060 time 0.53\n",
      "Epoch 370 Loss 0.065 time 0.44\n",
      "Epoch 371 Loss 0.056 time 0.55\n",
      "Epoch 372 Loss 0.058 time 0.45\n",
      "Epoch 373 Loss 0.060 time 0.55\n",
      "Epoch 374 Loss 0.060 time 0.45\n",
      "Epoch 375 Loss 0.061 time 0.48\n",
      "Epoch 376 Loss 0.058 time 0.43\n",
      "Epoch 377 Loss 0.063 time 0.45\n",
      "Epoch 378 Loss 0.060 time 0.45\n",
      "Epoch 379 Loss 0.062 time 0.46\n",
      "Epoch 380 Loss 0.057 time 0.44\n",
      "Epoch 381 Loss 0.062 time 0.46\n",
      "Epoch 382 Loss 0.062 time 0.45\n",
      "Epoch 383 Loss 0.058 time 0.44\n",
      "Epoch 384 Loss 0.061 time 0.46\n",
      "Epoch 385 Loss 0.060 time 0.46\n",
      "Epoch 386 Loss 0.057 time 0.50\n",
      "Epoch 387 Loss 0.060 time 0.50\n",
      "Epoch 388 Loss 0.060 time 0.52\n",
      "Epoch 389 Loss 0.060 time 0.45\n",
      "Epoch 390 Loss 0.061 time 0.45\n",
      "Epoch 391 Loss 0.057 time 0.46\n",
      "Epoch 392 Loss 0.058 time 0.44\n",
      "Epoch 393 Loss 0.060 time 0.43\n",
      "Epoch 394 Loss 0.061 time 0.43\n",
      "Epoch 395 Loss 0.058 time 0.44\n",
      "Epoch 396 Loss 0.058 time 0.41\n",
      "Epoch 397 Loss 0.059 time 0.42\n",
      "Epoch 398 Loss 0.059 time 0.45\n",
      "Epoch 399 Loss 0.063 time 0.49\n",
      "Epoch 400 Loss 0.059 time 0.55\n",
      "Epoch 401 Loss 0.060 time 0.52\n",
      "Epoch 402 Loss 0.060 time 0.54\n",
      "Epoch 403 Loss 0.061 time 0.50\n",
      "Epoch 404 Loss 0.059 time 0.42\n",
      "Epoch 405 Loss 0.058 time 0.45\n",
      "Epoch 406 Loss 0.061 time 0.42\n",
      "Epoch 407 Loss 0.060 time 0.48\n",
      "Epoch 408 Loss 0.057 time 0.54\n",
      "Epoch 409 Loss 0.055 time 0.55\n",
      "Epoch 410 Loss 0.061 time 0.46\n",
      "Epoch 411 Loss 0.057 time 0.44\n",
      "Epoch 412 Loss 0.062 time 0.44\n",
      "Epoch 413 Loss 0.062 time 0.44\n",
      "Epoch 414 Loss 0.055 time 0.46\n",
      "Epoch 415 Loss 0.056 time 0.44\n",
      "Epoch 416 Loss 0.055 time 0.44\n",
      "Epoch 417 Loss 0.058 time 0.44\n",
      "Epoch 418 Loss 0.059 time 0.46\n",
      "Epoch 419 Loss 0.056 time 0.48\n",
      "Epoch 420 Loss 0.060 time 0.53\n",
      "Epoch 421 Loss 0.060 time 0.45\n",
      "Epoch 422 Loss 0.057 time 0.43\n",
      "Epoch 423 Loss 0.058 time 0.47\n",
      "Epoch 424 Loss 0.058 time 0.47\n",
      "Epoch 425 Loss 0.060 time 0.44\n",
      "Epoch 426 Loss 0.061 time 0.52\n",
      "Epoch 427 Loss 0.059 time 0.42\n",
      "Epoch 428 Loss 0.057 time 0.46\n",
      "Epoch 429 Loss 0.060 time 0.48\n",
      "Epoch 430 Loss 0.058 time 0.51\n",
      "Epoch 431 Loss 0.057 time 0.53\n",
      "Epoch 432 Loss 0.059 time 0.58\n",
      "Epoch 433 Loss 0.059 time 0.79\n",
      "Epoch 434 Loss 0.057 time 0.55\n",
      "Epoch 435 Loss 0.061 time 0.56\n",
      "Epoch 436 Loss 0.063 time 0.58\n",
      "Epoch 437 Loss 0.059 time 0.46\n",
      "Epoch 438 Loss 0.058 time 0.44\n",
      "Epoch 439 Loss 0.057 time 0.52\n",
      "Epoch 440 Loss 0.054 time 0.47\n",
      "Epoch 441 Loss 0.057 time 0.54\n",
      "Epoch 442 Loss 0.060 time 0.60\n",
      "Epoch 443 Loss 0.062 time 0.49\n",
      "Epoch 444 Loss 0.056 time 0.52\n",
      "Epoch 445 Loss 0.057 time 0.53\n",
      "Epoch 446 Loss 0.058 time 0.61\n",
      "Epoch 447 Loss 0.058 time 0.54\n",
      "Epoch 448 Loss 0.060 time 0.54\n",
      "Epoch 449 Loss 0.061 time 0.57\n",
      "Epoch 450 Loss 0.062 time 0.53\n",
      "Epoch 451 Loss 0.060 time 0.61\n",
      "Epoch 452 Loss 0.058 time 0.48\n",
      "Epoch 453 Loss 0.059 time 0.57\n",
      "Epoch 454 Loss 0.058 time 0.62\n",
      "Epoch 455 Loss 0.054 time 0.52\n",
      "Epoch 456 Loss 0.061 time 0.57\n",
      "Epoch 457 Loss 0.058 time 0.60\n",
      "Epoch 458 Loss 0.056 time 0.55\n",
      "Epoch 459 Loss 0.057 time 0.58\n",
      "Epoch 460 Loss 0.057 time 0.52\n",
      "Epoch 461 Loss 0.057 time 0.66\n",
      "Epoch 462 Loss 0.059 time 0.49\n",
      "Epoch 463 Loss 0.055 time 0.52\n",
      "Epoch 464 Loss 0.059 time 0.52\n",
      "Epoch 465 Loss 0.052 time 0.50\n",
      "Epoch 466 Loss 0.054 time 0.61\n",
      "Epoch 467 Loss 0.058 time 0.53\n",
      "Epoch 468 Loss 0.055 time 0.58\n",
      "Epoch 469 Loss 0.061 time 0.51\n",
      "Epoch 470 Loss 0.059 time 0.54\n",
      "Epoch 471 Loss 0.058 time 0.57\n",
      "Epoch 472 Loss 0.059 time 0.60\n",
      "Epoch 473 Loss 0.057 time 0.58\n",
      "Epoch 474 Loss 0.058 time 0.57\n",
      "Epoch 475 Loss 0.053 time 0.57\n",
      "Epoch 476 Loss 0.058 time 0.53\n",
      "Epoch 477 Loss 0.057 time 0.53\n",
      "Epoch 478 Loss 0.055 time 0.53\n",
      "Epoch 479 Loss 0.058 time 0.58\n",
      "Epoch 480 Loss 0.057 time 0.57\n",
      "Epoch 481 Loss 0.058 time 0.54\n",
      "Epoch 482 Loss 0.058 time 0.68\n",
      "Epoch 483 Loss 0.058 time 0.73\n",
      "Epoch 484 Loss 0.055 time 0.68\n",
      "Epoch 485 Loss 0.060 time 0.59\n",
      "Epoch 486 Loss 0.055 time 0.54\n",
      "Epoch 487 Loss 0.057 time 0.61\n",
      "Epoch 488 Loss 0.056 time 0.50\n",
      "Epoch 489 Loss 0.058 time 0.53\n",
      "Epoch 490 Loss 0.059 time 0.49\n",
      "Epoch 491 Loss 0.054 time 0.53\n",
      "Epoch 492 Loss 0.060 time 0.61\n",
      "Epoch 493 Loss 0.055 time 0.60\n",
      "Epoch 494 Loss 0.059 time 0.51\n",
      "Epoch 495 Loss 0.055 time 0.55\n",
      "Epoch 496 Loss 0.056 time 0.63\n",
      "Epoch 497 Loss 0.054 time 0.57\n",
      "Epoch 498 Loss 0.056 time 0.56\n",
      "Epoch 499 Loss 0.058 time 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseAsyncIOLoop._handle_events(14, 1)\n",
      "handle: <Handle BaseAsyncIOLoop._handle_events(14, 1)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 239, in dispatch_shell\n",
      "    sys.stdout.flush()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in flush\n",
      "    if self.pub_thread.thread.is_alive():\n",
      "AttributeError: 'NoneType' object has no attribute 'thread'\n"
     ]
    }
   ],
   "source": [
    "opt['model'] = 'closed_loop'\n",
    "opt['out'] = 'closed_loop'\n",
    "rnnSMAP.funLSTM.trainLSTM(opt)\n",
    "\n",
    "out = opt['out']\n",
    "rootOut = rnnSMAP.kPath['Out_L3_NA']\n",
    "syr = 2015\n",
    "eyr = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 'closed_loop'\n",
    "testName = 'CONUSv16f1'\n",
    "rootDB = rnnSMAP.kPath['DB_L3_NA']\n",
    "rootOut = rnnSMAP.kPath['Out_L3_NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SMAP_AM.csv 0.03324484825134277\n",
      "running test\n",
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/APCP_FORA.csv 0.025861024856567383\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/DLWRF_FORA.csv 0.030211687088012695\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/DSWRF_FORA.csv 0.024955272674560547\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/TMP_2_FORA.csv 0.021469831466674805\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SPFH_2_FORA.csv 0.03443574905395508\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/VGRD_10_FORA.csv 0.03911089897155762\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/UGRD_10_FORA.csv 0.027565956115722656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'rnnSMAP.classLSTM.torchLSTM_closed_loop_cell' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /Users/rajdesai/Desktop/Hydro/output/L3_NA/closed_loop/test_CONUSv16f1_2017_2017_ep500.csv\n",
      "reading /Users/rajdesai/Desktop/Hydro/output/L3_NA/closed_loop/test_CONUSv16f1_2017_2017_ep500.csv\n"
     ]
    }
   ],
   "source": [
    "ds1 = rnnSMAP.classDB.DatasetPost(rootDB=rootDB, subsetName=testName, yrLst=[2017])# define dataset\n",
    "ds1.readData(var='SMAP_AM', field='SMAP')# read target\n",
    "ds1.readPred(rootOut=rootOut, out=out, drMC=0, field='LSTM')# read prediction\n",
    "statErr1 = ds1.statCalError(predField='LSTM', targetField='SMAP')# calculate error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/SMAP_AM.csv 0.029139995574951172\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/SMAP_AM.csv 0.024698972702026367\n",
      "running test\n",
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/APCP_FORA.csv 0.017364025115966797\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/APCP_FORA.csv 0.015365123748779297\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/DLWRF_FORA.csv 0.021539926528930664\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/DLWRF_FORA.csv 0.019514083862304688\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/DSWRF_FORA.csv 0.025316953659057617\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/DSWRF_FORA.csv 0.026781797409057617\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/TMP_2_FORA.csv 0.03287672996520996\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/TMP_2_FORA.csv 0.026353836059570312\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/SPFH_2_FORA.csv 0.022536039352416992\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/SPFH_2_FORA.csv 0.027792930603027344\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/VGRD_10_FORA.csv 0.021852731704711914\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/VGRD_10_FORA.csv 0.01846599578857422\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/UGRD_10_FORA.csv 0.0381619930267334\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/UGRD_10_FORA.csv 0.0327610969543457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'rnnSMAP.classLSTM.torchLSTM_closed_loop_cell' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /Users/rajdesai/Desktop/Hydro/output/L3_NA/closed_loop/test_CONUSv16f1_2015_2016_ep500.csv\n",
      "reading /Users/rajdesai/Desktop/Hydro/output/L3_NA/closed_loop/test_CONUSv16f1_2015_2016_ep500.csv\n"
     ]
    }
   ],
   "source": [
    "ds2 = rnnSMAP.classDB.DatasetPost(rootDB=rootDB, subsetName=testName, yrLst=[2015, 2016])\n",
    "ds2.readData(var='SMAP_AM', field='SMAP')\n",
    "ds2.readPred(rootOut=rootOut, out=out, drMC=0, field='LSTM')\n",
    "statErr2 = ds2.statCalError(predField='LSTM', targetField='SMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAGNCAYAAAA8QCmhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XucXWV97/HPj5mQq4BCtJaLQRJfJkZuhktgB4wIJfZYqoISFWkb4XBaaM/xqMWTU1Q0p2JbaXvEKja0gBqw2GqURKCAkQ1yCRAEzEECotykuREIyeT6O3/snTpsJsnOzN4z82Q+79drXq691rOe57eIa76z1nr23pGZSJKkwW+PgS5AkiQ1x9CWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLu5GIGBERGREHDHQtklrP0NaQFBFru/1sjYj13V5/aKDra4eIeKzbMW6JiK5urz/Wh36/GxEf38H2fep/SGwb61cR8bmGNkvq/w7jGtbfWt/38Prr10bENyPiPyLihYhYGhHnb2ecbT/n9vbYpMGmc6ALkAZCZo7ZthwRTwAfzcx/H7iKmhMRnZm5uTf7ZuYh3fq5E/hyZn6jZcXt3LjMXBERk4EfR8RPM/Nfum1/FDgL+Fy9xjcAbwTWdWvzNWAVMB54CZgIHMLLjcvMFW06BmlAeaUt9SAiOiLiLyLi8YhYUb+626e+7c0RsTkiZkXE0xGxMiL+KCKOi4iHIuL5iPhSt77Oi4hbIuJr9avDn0XECd22HxQRCyJiVUT8PCLO7rbtCxHxrYi4NiJeBM6MiOMj4q76OM9ExKUR0ZI/wCPignoNqyJifkT8Vn19Z0RcXv9vsSYi7o+IgyPik8B/AebUr2qv3tkYmfkQsBg4vGHT1dRCe5uzgG8B3T+28Sjg6sx8ITO3ZOZDmfm9PhyyVBRDW+rZx4FTgApwALAJuLTb9g7gUGpXgn8I/F/gfwJvr6//w4g4plv7E4AHgH2BLwDfjYi96tv+BXgEeD3wQeDSiDi+277vA64E9ga+U6/l/Hpf04B3Ax/t6wHX/1g4BzgVeF29pn/qVsObgIOBVwMfAV7MzC8CPwBmZ+aYzDzrFR2/cpzDqIXvsoZN/w94PiKm1l+fBVzV0OZO4G8i4sMR8cZdPESpeIa21LPzgAsz85nM7AI+C3wgIqJbm4szc0Nmzq+/viozV2Tmr4A7gCO6tX0yM7+SmZsy8yrgKeB3ImICcBjwv+p9LaYW0N3Db1FmLsjMrZm5PjPvzsx76leajwH/CJzYomP+bGY+npmbgE/Xa9yb2h8K+1AL7szMB3txC/qxiFgHLKH2h0pjIFNf95GIOBZ4ITOXNmz/Q2p/JHwSeLR+16Lx2B+r34XY9nPsLtYpDVqGttSgHswHAgu2/eIH7qd2vuxbb7YlM1d222098FzD6zHdXj/VMMwvgd+u/yzPzPUN2/bv9vrJhvomRcTCiHguIl4ALgL225Vj3I43AP/c7ZifATZQu9PwXWq3qq8Afh0Rfx8RI3ex/0Oo/Tc5h9odgp72nwe8h9qdg1eEema+mJmfzsxDqR3zzcC/RcSI7uNk5j7dfu7cxTqlQcvQlhpk7avvngbe0fDLf0QfJjg1vgXrIGqh+AwwtiEAD6qP/58lNez7deA+auG0F3AxEPTdk8CZDcc8MjMfrl/lfzEzDwOOBKYCf7yd+rar3s8/Ao9TewTRuH0ltVvgZ1EL8B31tRq4hNrt+v131FbaXRjaUs++CnwhIg6E/3yr0bv70N+B9QlpnRHxYWpX8jdSe677IPD5iBgeEUcCZwM7mtX9KmBNZq6NiLdQu3Jtha8Cn67fsiciXhMR760vHx8RR9YnvL0IbAS21vd7jtqz/V3xl8Cf1W+9N/pT4MSe/kCKiM9FxOERMSwiRlF7tv9rancnpN2eoS317IvAvwO31Gdt30HtCrO3fkztGfcqYDbw3sxcU7+qPwOYRC18rgU+kZnVHfT1P4CPRsRa4LL6Pn2Wmf9E7fb39+q33e+jNrEOao8FvgE8T+0PjaXAV+rb/gE4sX5b/comx6pSm3j2pz1s+9UObmkPA66h9t/xV9T+Td7V8Da4Jxrep/3ZZmqSShC13xmS2iUizgNOz8x3DnQtksrmlbYkSYUwtCVJKoS3xyVJKoRX2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiE6B7qARvvtt1+OGzduoMuQBr177713RWaOHeg6dsTzWWpOs+fzoAvtcePGsXjx4oEuQxr0IuKXA13Dzng+S81p9nz29rgkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCjHovjBEktQ3EdGn/TOzRZWo1QxtSdrN7Ch0I8JQLpi3xyVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVIimQjsiTo2IRyJiWURc2MP24RFxbX37XRExrr7+QxGxpNvP1og4vLWHIEnS0LDT0I6IDuAyYAYwCZgZEZMams0CVmfmeOBS4BKAzPxmZh6emYcDZwG/yMwlrTwASZKGimautI8GlmXm45m5EbgGOK2hzWnAlfXl64CTIiIa2sys7ytJknqhmdDeH3iy2+un6ut6bJOZm4E1wL4NbT4AzOtpgIg4NyIWR8Ti5cuXN1O3pEHK81lqn36ZiBYRxwDrMvOhnrZn5uWZOSUzp4wdO7Y/SpLUJp7PUvs0E9pPAwd2e31AfV2PbSKiE9gbWNlt+5ls5ypbkiQ1p5nQvgeYEBEHR8Se1AJ4fkOb+cDZ9eXTgVsyMwEiYg/g/fg8W5KkPuncWYPM3BwR5wM3AB3AFZn5cERcDCzOzPnAXODqiFgGrKIW7NucADyZmY+3vnxJkoaOnYY2QGYuABY0rLuo23IXcMZ29v0RcGzvS5QkSeAnokmSVAxDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKkTnQBcgSWre2rVr+d73vtenPr75zW/2ar+DDjqIadOm9Wls9Y2hLUkF+frXv87XPvUp3jZsWK/2fzew4Lzzdnm/rcB169axacuWXo2r1mgqtCPiVODvgA7gHzPzCw3bhwNXAW8DVgIfyMwn6tsOBb4G7EXt3/2ozOxq1QFI0lCydetWfnfrVv5m7dred9KLfbcA347o/ZhqiZ0+046IDuAyYAYwCZgZEZMams0CVmfmeOBS4JL6vp3AN4DzMvMtwNuBTS2rXpKkIaSZiWhHA8sy8/HM3AhcA5zW0OY04Mr68nXASRERwCnATzPzAYDMXJmZ3luRJKkXmgnt/YEnu71+qr6uxzaZuRlYA+wLvAnIiLghIu6LiE/2vWRJkoamdk9E6wQqwFHAOuDmiLg3M2/u3igizgXOhdrsREnl8nyW2qeZK+2ngQO7vT6gvq7HNvXn2HtTm5D2FPDjzFyRmeuABcCRjQNk5uWZOSUzp4wdO3bXj0LSoOH5LLVPM6F9DzAhIg6OiD2BM4H5DW3mA2fXl08HbsnMBG4A3hoRo+phfiLws9aULknS0LLT2+OZuTkizqcWwB3AFZn5cERcDCzOzPnAXODqiFgGrKIW7GTm6oj4ErXgT2BBZl7fpmORJGm31tQz7cxcQO3Wdvd1F3Vb7gLO2M6+36D2ti9JktQHfva4JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjaklSQzs5Ouvbo/1/dXUDnAIyrl/NfQJIKcsQRR3Dv8OH9Pu5i4IgJE/p9XL2coS1JBTnqqKN4aP161vXzuNU99qBy8sn9PKoaGdqSVJCRI0dy6IQJ3N3P41bHjKHyjnf086hqZGhLUmEqp5zCbf34fHkL8JOuLo4//vh+G1M9M7QlqTCV6dOpjhnTb+M9BPzWfvsxduzYfhtTPTO0Jakwxx13HHd2dbG5n8a7Dai8/e39NJp2xNCWpMLst99+7P/a1/JgP41XHTPGSWiDhKEtSQWqvP3tVPthnARu27KFSqXSD6NpZwxtSSpQ5eST++W59i+BLcOGccghh7R9LO2coS1JBZo2bRrVrVvJNo9TBaZNnUpEtHkkNcPQlqQCjRs3DvbckyfaPE51xAgqM2a0eRQ1y9CWpAJFBJWpU9v+XLs6bJjPswcRQ1uSClWZMYPqiBFt638V8KuNGznssMPaNoZ2jaEtSYWqVCrcNmxY2/q/Azjm0EPp7Oxs2xjaNYa2JBXqrW99K09v2sSKNvVf7eykcuqpbepdvWFoS1KhOjs7Ofaww7ijTf1XR42icuKJbepdvWFoS1LBKjNmUG3D7esu4P716znmmGNa3rd6z9CWpIJVTjiB6qhRLe93MTBp3DjG9OMXk2jnmgrtiDg1Ih6JiGURcWEP24dHxLX17XdFxLj6+nERsT4iltR/vtra8iVpaDv66KN5YP161re432qEnzc+CO00tCOiA7gMmAFMAmZGxKSGZrOA1Zk5HrgUuKTbtscy8/D6z3ktqluSBIwePZrJb3wj97S439te9Soq73hHi3tVXzVzpX00sCwzH8/MjcA1wGkNbU4DrqwvXwecFH7mnST1i8rJJ1Nt4a/crcAdGzb4oSqDUDOhvT/wZLfXT9XX9dgmMzcDa4B969sOjoj7I2JRREzraYCIODciFkfE4uXLl+/SAUgaXDyf+9+0k06i+qpXtay/h4Gxr3kNr3vd61rWp1qj3RPRngUOyswjgI8B34qIvRobZeblmTklM6eMHTu2zSVJaifP5/53/PHHc0dXF1ta1F+V2gQ3DT7NhPbTwIHdXh9QX9djm4joBPYGVmbmhsxcCZCZ9wKPAW/qa9GSpN8YO3Ysv7XffjzUov6qo0dTOeWUFvWmVmomtO8BJkTEwRGxJ3AmML+hzXzg7Pry6cAtmZkRMbY+kY2IeCMwAXi8NaVLkrapnHhiy748pAo+zx6kdhra9WfU5wM3AEuBb2fmwxFxcUT8Xr3ZXGDfiFhG7Tb4treFnQD8NCKWUJugdl5mrmr1QUjSUFc55RSqo0f3uZ9fAev32IMJEyb0vSi1XFMfo5OZC4AFDesu6rbcBZzRw37fAb7TxxolSTtRqVT435kk0Jd55LcDlWOOwTcADU5+Ipok7QYOOeQQNnd28qs+9lMdPtwvCRnEDG1J2g1EBJVjj+3zc+3q8OFUpvX47lwNAoa2JO0mKjNmUB0xotf7Pw883tXFEUcc0bqi1FKGtiTtJiqVCtVhw3q9/0+AoyZPZlgf+lB7GdqStJs4/PDD+eXGjazu5f7Vjg6O/53faWlNaq3WfwmrJGlAZCaZyas//YoPnmzKHKD2/VD/p4VVqZUMbUnaTdx///28cfhw+OwLvdr/BuAvDz+cH32mpWWphbw9Lkm7ieptt1HZuLHX+08FFv/sZ2zsQx9qL0NbknYT1YULqWzY0Ov99wImjBjBfffd17qi1FKGtiTtBjKT6t1309dPDK9s2ED1tttaUpNaz9CWpN3Ao48+ysitW1/2lYy9UdmwgerChS2pSa1naEvSbqBarfb5KhvgeKB6991kZgt6U6sZ2pK0G6jeeCOVl17qcz8HAK8CHnnkkT73pdYztCVpN1BdtKglV9oAFWpX7hp8DG1JKtxzzz3HitWreUuL+qu89BLVG25oUW9qJUNbkgp3++23c9zw4S37hV4BZ5APUoa2JBXutptvpvLiiy3rbyKw+vnnefbZZ1vWp1rD0JakwlVvuolKC2d77wEcv+eePtcehAxtSSrY2rVr+dkTTzClxf1W1q6levPNLe5VfWVoS1LB7rrrLo4YOZIRLe63kmloD0KGtiQVrLpoEZV161re79uAR375S15s4bNy9Z2hLUkFq/7wh1Q2b255v8OBI0eO5M4772x53+o9Q1uSCrV582bu+ulPOa5N/VfWraO6aFGbeldvGNqSVKgHHniAN+y5J69pU/+VzZup/vCHbepdvWFoS1KhqtUqlU2b2tb/VODuBx9kUxvH0K4xtCWpUNWFC6l0dbWt/1cDBw8fzpIlS9o2hnaNoS1JBcpMqnfe2bIvCdmeysaNfqTpIGJoS1KBHnvsMTo3beKgNo9T2bCB2xYubPMoapahLUkFqlarVCKINo9TAap33UW28GNS1XuGtiQVqHrjjVReeqnt4xwEjNiyhUcffbTtY2nnDG1JKlB10aK2P8/eZlqEXx4ySBjaklSY5cuX8+sVK5jcT+NVXnqJ6o039tNo2hFDW5IKc/vttzN1xAg6+mm8ClD98Y/7aTTtSFOhHRGnRsQjEbEsIi7sYfvwiLi2vv2uiBjXsP2giFgbER9vTdmSNHRVb7mFaf34RR5vAZavWsVzzz3Xb2OqZzsN7YjoAC4DZgCTgJkRMamh2SxgdWaOBy4FLmnY/iXA9wxIUgtUb7qJSj/O5t4DOG74cG6//fZ+G1M9a+ZK+2hgWWY+npkbgWuA0xranAZcWV++DjgpIgIgIn4f+AXwcGtKlqSha926dTz02GMc1c/jVl58keott/TzqGrUTGjvDzzZ7fVT9XU9tsnMzcAaYN+IGAP8OfDZHQ0QEedGxOKIWLx8+fJma5c0CHk+t9fdd9/NoSNHMrKfx61kUr3ppn4eVY3aPRHtM8Clmbl2R40y8/LMnJKZU8aOHdvmkiS1k+dzey1ZsoQjN2zo93HfBix57LF+H1cv19lEm6eBA7u9PqC+rqc2T0VEJ7A3sBI4Bjg9Ir4I7ANsjYiuzPxynyuXpCFoy5YtDN+6td/HHQ5sGYBx9XLNhPY9wISIOJhaOJ8JfLChzXzgbOAnwOnALVn7zLtp2xpExGeAtQa2JEm9s9PQzszNEXE+cAPQAVyRmQ9HxMXA4sycD8wFro6IZcAqasEuSZJaqJkrbTJzAbCgYd1F3Za7gDN20sdnelGfJEmq8xPRJEkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhrh+bNm8fkyZPp6Ohg8uTJzJs3b6BLkqQhq6kvDNHQNG/ePGbPns3cuXOpVCpUq1VmzZoFwMyZMwe4OkkaerzS1nbNmTOHuXPnMn36dIYNG8b06dOZO3cuc+bMGejSJGlI8kpb27V06VIqlcrL1lUqFZYuXTpAFUkCWJvJs/085pZ+Hk89M7S1XRMnTqRarTJ9+vT/XFetVpk4ceIAViUNbZMmTeKvR49mfmav9l/zwgvsvddevdr32IMP7tV+ah1DW9s1e/ZsZs2a9Ypn2t4elwbOjBkzePb553u9f0Swbs2aFlak/mRoa7tmzpzJHXfcwYwZM9iwYQPDhw/nnHPOcRKaJA0QJ6Jpu+bNm8f111/PwoUL2bhxIwsXLuT666/3bV+SNEAMbW2Xs8claXAxtLVdzh6XpMHF0NZ2bZs93p2zxyVp4Bja2q5ts8dvvfVWNm3axK233sqsWbOYPXv2QJcmSUOSs8e1XdtmiV9wwQUsXbqUiRMnMmfOHGePS9IAMbS1QzNnzjSkJWmQ8Pa4JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBWiqdCOiFMj4pGIWBYRF/awfXhEXFvffldEjKuvPzoiltR/HoiI97S2fLVKRPTpR5LUfjv9cJWI6AAuA04GngLuiYj5mfmzbs1mAaszc3xEnAlcAnwAeAiYkpmbI+L1wAMR8f3M3NzyI1GfZOYOt0fETttIktqrmSvto4Flmfl4Zm4ErgFOa2hzGnBlffk64KSIiMxc1y2gRwD+1pckqZeaCe39gSe7vX6qvq7HNvWQXgPsCxARx0TEw8CDwHleZUuS1Dttn4iWmXdl5luAo4BPRcSIxjYRcW5ELI6IxcuXL293SZLayPNZap9mQvtp4MBurw+or+uxTUR0AnsDK7s3yMylwFpgcuMAmXl5Zk7JzCljx45tvnpJg47ns9Q+zYT2PcCEiDg4IvYEzgTmN7SZD5xdXz4duCUzs75PJ0BEvAF4M/BESyqXJGmI2ens8frM7/OBG4AO4IrMfDgiLgYWZ+Z8YC5wdUQsA1ZRC3aACnBhRGwCtgJ/nJkr2nEgkiTt7pr6Pu3MXAAsaFh3UbflLuCMHva7Gri6jzVKkiT8RDRJkophaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSpEU9+nrfLNufhiRu+1F+PHj+91Hz/4wQ92eZ9rvvUtLvrMZ3jTm97U63ElSTWG9hDx5a98hV8/9xyv6ehg6pgxu7x/Bfjqhz/cdPstmfzwhRcAmPmhDxnaktQChvYQ8eyvf82CBQv4g/e/n7PWrOEDvelkzZqmmr0IzBw1ipOmTuW6BQvYZ599ejOaJKmBz7SHkHe9613cdPvtfGLfffl8ZyfZhjGeBKaNHs3r3/teFi5aZGBLUgsZ2kPMYYcdxl0PPsh3x4/nD0aMYEML+74XmDpyJB+aPZvLr7qKYcOGtbB3SZKhPQS9/vWvZ9HixbxwwgmcMmoUK1vQ53eBU0eN4u+/8Q0+8alPEREt6FWS1J2hPUSNHj2a7yxcyNGzZjF11CiW9aGvL3V08CevfjULfvQj3vve97asRknSyzkRbQjbY489uPDTn+Y7//qvjP9E7/+v8DHgxbyAo446qnXFSZJewdAewn7+85/zu9Onc/qKFWz97MZe33Z5FPjmqL/mhVWr+OLf/i0dHR2tLFOSVOft8SFq0aJFTJsyhU8++yxf3Nj7wAaYANy5bh33XnEF75sxg5deeqlVZUqSujG0h6Cr/vmfOWPGDL754ouck61549drgBvXrWOf227jxClTeOaZZ1rSryTpNwztISQz+Ys//3M+8yd/wo/Wr+edLe5/T+Cfurp4z7JlHHvooTzwwAMtHkGShjZDe4jo6urig+95D//+5S9z57p1TGrTOAHM3ryZv1q5kncedxzXX399m0aSpKHH0B4ifu+kk8gbb+SWdet4bT+M9wFg/rp1fPSMM/j+97/fDyNK0u7P0B4i7r7vPv5h/XpG9uOYU4Fz1q/nvvvu68dRJUXEdn92tt0PRhrcfMvXEDIQp6Knv9T/skUTTDX4eKUtSVIhDG1JkgrRVGhHxKkR8UhELIuIC3vYPjwirq1vvysixtXXnxwR90bEg/X/fUdry5ckaejYaWhHRAdwGTADmATMjIjGdwzNAlZn5njgUuCS+voVwLsz863A2cDVrSpckqShppkr7aOBZZn5eGZuBK4BTmtocxpwZX35OuCkiIjMvD8zt3001sPAyIgY3orCJUkaapoJ7f2BJ7u9fqq+rsc2mbkZWAPs29DmfcB9mbmhcYCIODciFkfE4uXLlzdbu6RByPNZap9+ectXRLyF2i3zU3ranpmXA5cDTJkyxfcqtMkVwKh+HnMxtVs1Gjo8n6X2aSa0nwYO7Pb6gPq6nto8FRGdwN7ASoCIOAD4N+AjmflYnytWr3z24otZ+uCDvd7/qquv5iNnnbXL+x0Ywfve975ejytJ+o1mQvseYEJEHEwtnM8EPtjQZj61iWY/AU4HbsnMjIh9gOuBCzPz9taVrV31Z5/4RJ/2/9rVV/PVq65qUTWSpN7Y6TPt+jPq84EbgKXAtzPz4Yi4OCJ+r95sLrBvRCwDPgZse1vY+cB44KKIWFL/6Y+PvpYkabfT1DPtzFwALGhYd1G35S7gjB72+zzw+T7WKEmS8BPRJEkqhqEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCdA12ABoeI6FObzGxlOZKkHhjaAgxdSSqBt8clSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhWgqtCPi1Ih4JCKWRcSFPWwfHhHX1rffFRHj6uv3jYhbI2JtRHy5taVLkjS07DS0I6IDuAyYAUwCZkbEpIZms4DVmTkeuBS4pL6+C/gL4OMtq1iSpCGqmSvto4Flmfl4Zm4ErgFOa2hzGnBlffk64KSIiMx8KTOr1MJbkiT1QTOhvT/wZLfXT9XX9dgmMzcDa4B9my0iIs6NiMURsXj58uXN7iZpEPJ8ltpnUExEy8zLM3NKZk4ZO3bsQJcjqQ88n6X2aSa0nwYO7Pb6gPq6HttERCewN7CyFQVKkqSaZkL7HmBCRBwcEXsCZwLzG9rMB86uL58O3JJ+16MkSS210+/TzszNEXE+cAPQAVyRmQ9HxMXA4sycD8wFro6IZcAqasEOQEQ8AewF7BkRvw+ckpk/a/2hSJK0e9tpaANk5gJgQcO6i7otdwFnbGffcX2oT5Ik1Q2KiWiSJGnnDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQ1g7NmzePyZMn09HRweTJk5k3b95AlyRJQ1ahj9jzAAADW0lEQVRTX82poWnevHnMnj2buXPnUqlUqFarzJo1C4CZM2cOcHWSNPR4pa3tmjNnDnPnzmX69OkMGzaM6dOnM3fuXObMmTPQpUnSkGRoa7uWLl1KpVJ52bpKpcLSpUsHqCJJGtoMbW3XxIkTqVarL1tXrVaZOHHiAFUkSUOboa3tmj17NrNmzeLWW29l06ZN3HrrrcyaNYvZs2cPdGmSNCQ5EU3btW2y2QUXXMDSpUuZOHEic+bMcRKaJA0QQ1s7NHPmTENakgYJb49LklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCRGYOdA0vExHLgV8OdB1SAd6QmWMHuogd8XyWmtbU+TzoQluSJPXM2+OSJBXC0JYkqRCGtiRJhTC0h6iI2Cci/rgX+y2IiH3aUZOkvunteV3f979HxKhW16TWciLaEBUR44AfZObkhvWdmbl5QIqS1CfbO6+b3PcJYEpmrmhxWWqhzoEuQAPmC8AhEbEE2AR0AauBNwNviojvAgcCI4C/y8zL4TcnNjAGWAhUgeOAp4HTMnN9Px+HpN/ofl7fBPwH8H5gOPBvmfnpiBgNfBs4AOgAPge8Dvht4NaIWJGZ0wekeu2UV9pDVPe/yCPi7cD1wOTM/EV9+2syc1VEjATuAU7MzJUNob2M2l/mSyLi28D8zPxG/x+NJHjFeX0KcDrwX4EA5gNfBMYCp2bmOfV99s7MNV5pl8Fn2trm7m2BXfenEfEAcCe1K+4JPezzi8xcUl++FxjX3hIl7YJT6j/3A/dRu4s2AXgQODkiLomIaZm5ZgBr1C7y9ri2eWnbQv3K+53A1MxcFxE/onabvNGGbstbgJHtLFDSLgngLzPza6/YEHEk8C7g8xFxc2Ze3O/VqVe80h66XgRetZ1tewOr64H9ZuDY/itLUh90P69vAP4oIsYARMT+EfHaiPhtYF39UdZfAUf2sK8GKa+0h6j68+nbI+IhYD3wXLfNPwTOi4ilwCPUbpFLGuQazuuFwLeAn0QEwFrgw8B44K8iYiu1Saj/rb775cAPI+IZJ6INXk5EkySpEN4elySpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRC/H8ehkQTUBm1WwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "strE = 'RMSE'\n",
    "dataErr = [getattr(statErr1, strE), getattr(statErr2, strE)]\n",
    "fig = rnnSMAP.funPost.plotBox(dataErr, labelC=['train', 'test'], title='Closed loop ' + strE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
