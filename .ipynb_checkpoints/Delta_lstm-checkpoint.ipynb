{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rnnSMAP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load rnnSMAP\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(rnnSMAP)\n",
    "rnnSMAP.reload()\n",
    "\n",
    "opt = rnnSMAP.classLSTM.optLSTM(\n",
    "    rootDB=rnnSMAP.kPath['DB_L3_NA'],\n",
    "    rootOut=rnnSMAP.kPath['Out_L3_NA'],\n",
    "    syr=2017, eyr=2017,\n",
    "    var='varLst_Forcing', varC='varConstLst_Noah',\n",
    "    train='CONUSv16f1', dr=0.5, modelOpt='relu',\n",
    "    target='SMAP_AM',gpu=0, loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: overwriting existed optFile. Delete manually.\n",
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/APCP_FORA.csv 0.024023056030273438\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/DLWRF_FORA.csv 0.021474123001098633\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/DSWRF_FORA.csv 0.014597892761230469\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/TMP_2_FORA.csv 0.014528036117553711\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SPFH_2_FORA.csv 0.014679193496704102\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/VGRD_10_FORA.csv 0.014405250549316406\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/UGRD_10_FORA.csv 0.014168977737426758\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SMAP_AM.csv 0.018004894256591797\n",
      "Epoch 1 Loss 0.390 time 7.14\n",
      "Epoch 2 Loss 0.194 time 6.83\n",
      "Epoch 3 Loss 0.153 time 6.55\n",
      "Epoch 4 Loss 0.144 time 6.75\n",
      "Epoch 5 Loss 0.139 time 6.73\n",
      "Epoch 6 Loss 0.134 time 6.66\n",
      "Epoch 7 Loss 0.129 time 6.91\n",
      "Epoch 8 Loss 0.113 time 6.75\n",
      "Epoch 9 Loss 0.110 time 6.66\n",
      "Epoch 10 Loss 0.097 time 6.88\n",
      "Epoch 11 Loss 0.095 time 6.67\n",
      "Epoch 12 Loss 0.100 time 6.61\n",
      "Epoch 13 Loss 0.099 time 6.81\n",
      "Epoch 14 Loss 0.097 time 7.05\n",
      "Epoch 15 Loss 0.096 time 6.68\n",
      "Epoch 16 Loss 0.090 time 6.90\n",
      "Epoch 17 Loss 0.087 time 6.74\n",
      "Epoch 18 Loss 0.093 time 6.51\n",
      "Epoch 19 Loss 0.089 time 6.82\n",
      "Epoch 20 Loss 0.089 time 6.77\n",
      "Epoch 21 Loss 0.080 time 6.83\n",
      "Epoch 22 Loss 0.085 time 6.77\n",
      "Epoch 23 Loss 0.085 time 6.84\n",
      "Epoch 24 Loss 0.081 time 7.22\n",
      "Epoch 25 Loss 0.073 time 6.88\n",
      "Epoch 26 Loss 0.077 time 6.76\n",
      "Epoch 27 Loss 0.078 time 6.80\n",
      "Epoch 28 Loss 0.075 time 7.02\n",
      "Epoch 29 Loss 0.073 time 6.64\n",
      "Epoch 30 Loss 0.077 time 6.83\n",
      "Epoch 31 Loss 0.076 time 6.52\n",
      "Epoch 32 Loss 0.077 time 6.94\n",
      "Epoch 33 Loss 0.071 time 6.66\n",
      "Epoch 34 Loss 0.068 time 6.52\n",
      "Epoch 35 Loss 0.081 time 6.72\n",
      "Epoch 36 Loss 0.072 time 6.75\n",
      "Epoch 37 Loss 0.066 time 8.07\n",
      "Epoch 38 Loss 0.070 time 7.22\n",
      "Epoch 39 Loss 0.066 time 6.76\n",
      "Epoch 40 Loss 0.067 time 6.70\n",
      "Epoch 41 Loss 0.070 time 6.83\n",
      "Epoch 42 Loss 0.073 time 6.74\n",
      "Epoch 43 Loss 0.068 time 6.68\n",
      "Epoch 44 Loss 0.064 time 6.67\n",
      "Epoch 45 Loss 0.068 time 6.70\n",
      "Epoch 46 Loss 0.067 time 6.76\n",
      "Epoch 47 Loss 0.067 time 6.74\n",
      "Epoch 48 Loss 0.065 time 6.89\n",
      "Epoch 49 Loss 0.064 time 6.50\n",
      "Epoch 50 Loss 0.064 time 6.71\n",
      "Epoch 51 Loss 0.068 time 6.53\n",
      "Epoch 52 Loss 0.062 time 6.69\n",
      "Epoch 53 Loss 0.064 time 6.45\n",
      "Epoch 54 Loss 0.065 time 6.48\n",
      "Epoch 55 Loss 0.061 time 6.81\n",
      "Epoch 56 Loss 0.066 time 6.74\n",
      "Epoch 57 Loss 0.064 time 6.73\n",
      "Epoch 58 Loss 0.063 time 6.79\n",
      "Epoch 59 Loss 0.062 time 7.20\n",
      "Epoch 60 Loss 0.063 time 6.99\n",
      "Epoch 61 Loss 0.065 time 6.77\n",
      "Epoch 62 Loss 0.059 time 6.67\n",
      "Epoch 63 Loss 0.063 time 6.68\n",
      "Epoch 64 Loss 0.056 time 6.80\n",
      "Epoch 65 Loss 0.062 time 6.62\n",
      "Epoch 66 Loss 0.062 time 7.70\n",
      "Epoch 67 Loss 0.059 time 6.67\n",
      "Epoch 68 Loss 0.061 time 6.79\n",
      "Epoch 69 Loss 0.057 time 7.80\n",
      "Epoch 70 Loss 0.060 time 8.92\n",
      "Epoch 71 Loss 0.060 time 7.21\n",
      "Epoch 72 Loss 0.058 time 6.76\n",
      "Epoch 73 Loss 0.058 time 7.27\n",
      "Epoch 74 Loss 0.058 time 6.86\n",
      "Epoch 75 Loss 0.058 time 6.96\n",
      "Epoch 76 Loss 0.060 time 6.83\n",
      "Epoch 77 Loss 0.054 time 6.66\n",
      "Epoch 78 Loss 0.058 time 6.85\n",
      "Epoch 79 Loss 0.057 time 6.84\n",
      "Epoch 80 Loss 0.057 time 7.35\n",
      "Epoch 81 Loss 0.060 time 8.13\n",
      "Epoch 82 Loss 0.055 time 6.90\n",
      "Epoch 83 Loss 0.055 time 7.12\n",
      "Epoch 84 Loss 0.058 time 6.75\n",
      "Epoch 85 Loss 0.054 time 7.03\n",
      "Epoch 86 Loss 0.054 time 7.01\n",
      "Epoch 87 Loss 0.055 time 8.24\n",
      "Epoch 88 Loss 0.053 time 6.96\n",
      "Epoch 89 Loss 0.056 time 6.88\n",
      "Epoch 90 Loss 0.057 time 6.89\n",
      "Epoch 91 Loss 0.055 time 7.14\n",
      "Epoch 92 Loss 0.056 time 6.78\n",
      "Epoch 93 Loss 0.056 time 7.74\n",
      "Epoch 94 Loss 0.052 time 6.70\n",
      "Epoch 95 Loss 0.057 time 6.79\n",
      "Epoch 96 Loss 0.052 time 6.72\n",
      "Epoch 97 Loss 0.051 time 6.83\n",
      "Epoch 98 Loss 0.051 time 6.88\n",
      "Epoch 99 Loss 0.051 time 6.75\n",
      "Epoch 100 Loss 0.053 time 6.89\n",
      "Epoch 101 Loss 0.050 time 6.73\n",
      "Epoch 102 Loss 0.054 time 7.54\n",
      "Epoch 103 Loss 0.051 time 6.96\n",
      "Epoch 104 Loss 0.051 time 7.16\n",
      "Epoch 105 Loss 0.054 time 6.62\n",
      "Epoch 106 Loss 0.052 time 6.69\n",
      "Epoch 107 Loss 0.053 time 6.79\n",
      "Epoch 108 Loss 0.050 time 6.70\n",
      "Epoch 109 Loss 0.052 time 6.55\n",
      "Epoch 110 Loss 0.053 time 7.27\n",
      "Epoch 111 Loss 0.057 time 7.34\n",
      "Epoch 112 Loss 0.050 time 6.94\n",
      "Epoch 113 Loss 0.053 time 6.79\n",
      "Epoch 114 Loss 0.051 time 7.84\n",
      "Epoch 115 Loss 0.050 time 6.85\n",
      "Epoch 116 Loss 0.052 time 6.70\n",
      "Epoch 117 Loss 0.052 time 6.57\n",
      "Epoch 118 Loss 0.050 time 6.70\n",
      "Epoch 119 Loss 0.049 time 1968.29\n",
      "Epoch 120 Loss 0.051 time 8.92\n",
      "Epoch 121 Loss 0.049 time 9.15\n",
      "Epoch 122 Loss 0.051 time 7.35\n",
      "Epoch 123 Loss 0.050 time 6.90\n",
      "Epoch 124 Loss 0.048 time 6.76\n",
      "Epoch 125 Loss 0.048 time 6.77\n",
      "Epoch 126 Loss 0.049 time 7.13\n",
      "Epoch 127 Loss 0.050 time 6.78\n",
      "Epoch 128 Loss 0.048 time 7.30\n",
      "Epoch 129 Loss 0.047 time 6.76\n",
      "Epoch 130 Loss 0.046 time 6.92\n",
      "Epoch 131 Loss 0.048 time 6.97\n",
      "Epoch 132 Loss 0.050 time 6.83\n",
      "Epoch 133 Loss 0.047 time 6.52\n",
      "Epoch 134 Loss 0.050 time 6.65\n",
      "Epoch 135 Loss 0.047 time 6.77\n",
      "Epoch 136 Loss 0.048 time 6.72\n",
      "Epoch 137 Loss 0.048 time 7.36\n",
      "Epoch 138 Loss 0.047 time 9.87\n",
      "Epoch 139 Loss 0.046 time 7.19\n",
      "Epoch 140 Loss 0.047 time 6.88\n",
      "Epoch 141 Loss 0.044 time 7.34\n",
      "Epoch 142 Loss 0.048 time 7.62\n",
      "Epoch 143 Loss 0.049 time 7.00\n",
      "Epoch 144 Loss 0.045 time 6.73\n",
      "Epoch 145 Loss 0.048 time 6.80\n",
      "Epoch 146 Loss 0.045 time 6.66\n",
      "Epoch 147 Loss 0.047 time 6.86\n",
      "Epoch 148 Loss 0.044 time 6.77\n",
      "Epoch 149 Loss 0.045 time 6.54\n",
      "Epoch 150 Loss 0.048 time 7.05\n",
      "Epoch 151 Loss 0.047 time 7.20\n",
      "Epoch 152 Loss 0.047 time 6.84\n",
      "Epoch 153 Loss 0.046 time 6.98\n",
      "Epoch 154 Loss 0.044 time 6.75\n",
      "Epoch 155 Loss 0.045 time 7.14\n",
      "Epoch 156 Loss 0.047 time 6.96\n",
      "Epoch 157 Loss 0.046 time 6.67\n",
      "Epoch 158 Loss 0.043 time 6.94\n",
      "Epoch 159 Loss 0.043 time 8.10\n",
      "Epoch 160 Loss 0.047 time 7.48\n",
      "Epoch 161 Loss 0.045 time 6.70\n",
      "Epoch 162 Loss 0.049 time 6.94\n",
      "Epoch 163 Loss 0.047 time 6.92\n",
      "Epoch 164 Loss 0.046 time 6.95\n",
      "Epoch 165 Loss 0.046 time 6.70\n",
      "Epoch 166 Loss 0.044 time 6.99\n",
      "Epoch 167 Loss 0.046 time 6.97\n",
      "Epoch 168 Loss 0.048 time 6.68\n",
      "Epoch 169 Loss 0.045 time 6.56\n",
      "Epoch 170 Loss 0.048 time 6.93\n",
      "Epoch 171 Loss 0.043 time 6.92\n",
      "Epoch 172 Loss 0.040 time 6.88\n",
      "Epoch 173 Loss 0.046 time 6.92\n",
      "Epoch 174 Loss 0.044 time 6.95\n",
      "Epoch 175 Loss 0.043 time 6.88\n",
      "Epoch 176 Loss 0.044 time 6.80\n",
      "Epoch 177 Loss 0.042 time 6.95\n",
      "Epoch 178 Loss 0.042 time 6.73\n",
      "Epoch 179 Loss 0.042 time 6.55\n",
      "Epoch 180 Loss 0.042 time 6.60\n",
      "Epoch 181 Loss 0.042 time 6.92\n",
      "Epoch 182 Loss 0.043 time 6.75\n",
      "Epoch 183 Loss 0.044 time 6.71\n",
      "Epoch 184 Loss 0.042 time 6.52\n",
      "Epoch 185 Loss 0.045 time 7.10\n",
      "Epoch 186 Loss 0.044 time 6.80\n",
      "Epoch 187 Loss 0.041 time 6.82\n",
      "Epoch 188 Loss 0.042 time 6.59\n",
      "Epoch 189 Loss 0.044 time 6.44\n",
      "Epoch 190 Loss 0.041 time 7.18\n",
      "Epoch 191 Loss 0.042 time 6.69\n",
      "Epoch 192 Loss 0.044 time 6.62\n",
      "Epoch 193 Loss 0.045 time 6.81\n",
      "Epoch 194 Loss 0.045 time 6.83\n",
      "Epoch 195 Loss 0.043 time 7.47\n",
      "Epoch 196 Loss 0.044 time 6.74\n",
      "Epoch 197 Loss 0.044 time 6.73\n",
      "Epoch 198 Loss 0.043 time 7.30\n",
      "Epoch 199 Loss 0.039 time 6.62\n",
      "Epoch 200 Loss 0.043 time 6.61\n",
      "Epoch 201 Loss 0.042 time 6.71\n",
      "Epoch 202 Loss 0.041 time 6.52\n",
      "Epoch 203 Loss 0.042 time 6.66\n",
      "Epoch 204 Loss 0.043 time 6.68\n",
      "Epoch 205 Loss 0.041 time 6.66\n",
      "Epoch 206 Loss 0.041 time 6.54\n",
      "Epoch 207 Loss 0.042 time 6.71\n",
      "Epoch 208 Loss 0.042 time 6.83\n",
      "Epoch 209 Loss 0.042 time 6.47\n",
      "Epoch 210 Loss 0.041 time 6.57\n",
      "Epoch 211 Loss 0.039 time 6.72\n",
      "Epoch 212 Loss 0.041 time 6.93\n",
      "Epoch 213 Loss 0.041 time 6.89\n",
      "Epoch 214 Loss 0.043 time 6.71\n",
      "Epoch 215 Loss 0.038 time 6.88\n",
      "Epoch 216 Loss 0.042 time 6.60\n",
      "Epoch 217 Loss 0.041 time 6.89\n",
      "Epoch 218 Loss 0.040 time 6.58\n",
      "Epoch 219 Loss 0.040 time 6.62\n",
      "Epoch 220 Loss 0.040 time 6.62\n",
      "Epoch 221 Loss 0.041 time 6.74\n",
      "Epoch 222 Loss 0.040 time 6.90\n",
      "Epoch 223 Loss 0.042 time 6.64\n",
      "Epoch 224 Loss 0.040 time 6.65\n",
      "Epoch 225 Loss 0.040 time 6.80\n",
      "Epoch 226 Loss 0.040 time 6.76\n",
      "Epoch 227 Loss 0.041 time 6.78\n",
      "Epoch 228 Loss 0.039 time 6.90\n",
      "Epoch 229 Loss 0.040 time 7.10\n",
      "Epoch 230 Loss 0.039 time 7.43\n",
      "Epoch 231 Loss 0.039 time 6.53\n",
      "Epoch 232 Loss 0.042 time 6.80\n",
      "Epoch 233 Loss 0.040 time 6.66\n",
      "Epoch 234 Loss 0.041 time 6.63\n",
      "Epoch 235 Loss 0.039 time 6.58\n",
      "Epoch 236 Loss 0.039 time 6.91\n",
      "Epoch 237 Loss 0.038 time 9.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238 Loss 0.041 time 7.26\n",
      "Epoch 239 Loss 0.041 time 9.02\n",
      "Epoch 240 Loss 0.040 time 11.94\n",
      "Epoch 241 Loss 0.038 time 7.39\n",
      "Epoch 242 Loss 0.040 time 9.30\n",
      "Epoch 243 Loss 0.041 time 7.77\n",
      "Epoch 244 Loss 0.040 time 8.45\n",
      "Epoch 245 Loss 0.038 time 8.60\n",
      "Epoch 246 Loss 0.041 time 8.89\n",
      "Epoch 247 Loss 0.037 time 9.63\n",
      "Epoch 248 Loss 0.037 time 8.86\n",
      "Epoch 249 Loss 0.040 time 10.59\n",
      "Epoch 250 Loss 0.038 time 10.03\n",
      "Epoch 251 Loss 0.039 time 8.20\n",
      "Epoch 252 Loss 0.038 time 7.56\n",
      "Epoch 253 Loss 0.038 time 7.09\n",
      "Epoch 254 Loss 0.037 time 8.20\n",
      "Epoch 255 Loss 0.037 time 9.05\n",
      "Epoch 256 Loss 0.038 time 10.03\n",
      "Epoch 257 Loss 0.038 time 8.89\n",
      "Epoch 258 Loss 0.039 time 7.15\n",
      "Epoch 259 Loss 0.038 time 9.28\n",
      "Epoch 260 Loss 0.038 time 9.12\n",
      "Epoch 261 Loss 0.039 time 7.63\n",
      "Epoch 262 Loss 0.035 time 7.83\n",
      "Epoch 263 Loss 0.039 time 7.30\n",
      "Epoch 264 Loss 0.036 time 6.80\n",
      "Epoch 265 Loss 0.038 time 8.02\n",
      "Epoch 266 Loss 0.039 time 8.28\n",
      "Epoch 267 Loss 0.039 time 8.55\n",
      "Epoch 268 Loss 0.038 time 7.04\n",
      "Epoch 269 Loss 0.036 time 6.94\n",
      "Epoch 270 Loss 0.037 time 6.93\n",
      "Epoch 271 Loss 0.038 time 7.15\n",
      "Epoch 272 Loss 0.038 time 6.76\n",
      "Epoch 273 Loss 0.036 time 6.92\n",
      "Epoch 274 Loss 0.036 time 6.89\n",
      "Epoch 275 Loss 0.037 time 7.15\n",
      "Epoch 276 Loss 0.038 time 6.86\n",
      "Epoch 277 Loss 0.036 time 6.75\n",
      "Epoch 278 Loss 0.038 time 6.93\n",
      "Epoch 279 Loss 0.035 time 6.74\n",
      "Epoch 280 Loss 0.037 time 6.95\n",
      "Epoch 281 Loss 0.036 time 6.61\n",
      "Epoch 282 Loss 0.035 time 6.78\n",
      "Epoch 283 Loss 0.037 time 6.72\n",
      "Epoch 284 Loss 0.035 time 6.86\n",
      "Epoch 285 Loss 0.036 time 6.79\n",
      "Epoch 286 Loss 0.035 time 6.71\n",
      "Epoch 287 Loss 0.035 time 7.05\n",
      "Epoch 288 Loss 0.036 time 6.99\n",
      "Epoch 289 Loss 0.036 time 7.00\n",
      "Epoch 290 Loss 0.035 time 6.87\n",
      "Epoch 291 Loss 0.036 time 6.97\n",
      "Epoch 292 Loss 0.035 time 7.08\n",
      "Epoch 293 Loss 0.036 time 6.70\n",
      "Epoch 294 Loss 0.035 time 6.61\n",
      "Epoch 295 Loss 0.035 time 6.93\n",
      "Epoch 296 Loss 0.036 time 6.80\n",
      "Epoch 297 Loss 0.036 time 7.49\n",
      "Epoch 298 Loss 0.037 time 6.88\n",
      "Epoch 299 Loss 0.036 time 6.81\n",
      "Epoch 300 Loss 0.038 time 6.91\n",
      "Epoch 301 Loss 0.035 time 6.92\n",
      "Epoch 302 Loss 0.035 time 6.69\n",
      "Epoch 303 Loss 0.036 time 6.94\n",
      "Epoch 304 Loss 0.034 time 6.91\n",
      "Epoch 305 Loss 0.035 time 7.00\n",
      "Epoch 306 Loss 0.037 time 6.86\n",
      "Epoch 307 Loss 0.034 time 6.75\n",
      "Epoch 308 Loss 0.035 time 7.59\n",
      "Epoch 309 Loss 0.037 time 6.95\n",
      "Epoch 310 Loss 0.034 time 7.07\n",
      "Epoch 311 Loss 0.035 time 6.54\n",
      "Epoch 312 Loss 0.035 time 6.72\n",
      "Epoch 313 Loss 0.036 time 6.99\n",
      "Epoch 314 Loss 0.035 time 7.01\n",
      "Epoch 315 Loss 0.036 time 7.06\n",
      "Epoch 316 Loss 0.034 time 7.00\n",
      "Epoch 317 Loss 0.035 time 6.59\n",
      "Epoch 318 Loss 0.036 time 6.74\n",
      "Epoch 319 Loss 0.034 time 6.98\n",
      "Epoch 320 Loss 0.036 time 6.80\n",
      "Epoch 321 Loss 0.033 time 6.70\n",
      "Epoch 322 Loss 0.035 time 8.79\n",
      "Epoch 323 Loss 0.035 time 8.16\n",
      "Epoch 324 Loss 0.035 time 6.73\n",
      "Epoch 325 Loss 0.036 time 7.09\n",
      "Epoch 326 Loss 0.034 time 6.84\n",
      "Epoch 327 Loss 0.036 time 6.89\n",
      "Epoch 328 Loss 0.036 time 6.94\n",
      "Epoch 329 Loss 0.036 time 6.91\n",
      "Epoch 330 Loss 0.034 time 6.90\n",
      "Epoch 331 Loss 0.036 time 7.48\n",
      "Epoch 332 Loss 0.034 time 7.40\n",
      "Epoch 333 Loss 0.032 time 7.14\n",
      "Epoch 334 Loss 0.035 time 6.91\n",
      "Epoch 335 Loss 0.033 time 6.79\n",
      "Epoch 336 Loss 0.033 time 7.03\n",
      "Epoch 337 Loss 0.033 time 6.80\n",
      "Epoch 338 Loss 0.035 time 6.90\n",
      "Epoch 339 Loss 0.034 time 6.96\n",
      "Epoch 340 Loss 0.036 time 7.22\n",
      "Epoch 341 Loss 0.034 time 7.29\n",
      "Epoch 342 Loss 0.032 time 6.84\n",
      "Epoch 343 Loss 0.033 time 6.87\n",
      "Epoch 344 Loss 0.035 time 7.26\n",
      "Epoch 345 Loss 0.034 time 7.23\n",
      "Epoch 346 Loss 0.034 time 6.91\n",
      "Epoch 347 Loss 0.034 time 7.02\n",
      "Epoch 348 Loss 0.032 time 7.05\n",
      "Epoch 349 Loss 0.034 time 6.98\n",
      "Epoch 350 Loss 0.035 time 7.26\n",
      "Epoch 351 Loss 0.032 time 8.03\n",
      "Epoch 352 Loss 0.032 time 6.98\n",
      "Epoch 353 Loss 0.036 time 8.27\n",
      "Epoch 354 Loss 0.034 time 11.93\n",
      "Epoch 355 Loss 0.034 time 9.32\n",
      "Epoch 356 Loss 0.034 time 9.34\n",
      "Epoch 357 Loss 0.034 time 7.95\n",
      "Epoch 358 Loss 0.032 time 15.24\n",
      "Epoch 359 Loss 0.033 time 8.78\n",
      "Epoch 360 Loss 0.034 time 8.24\n",
      "Epoch 361 Loss 0.035 time 9.50\n",
      "Epoch 362 Loss 0.033 time 9.20\n",
      "Epoch 363 Loss 0.033 time 8.30\n",
      "Epoch 364 Loss 0.033 time 7.18\n",
      "Epoch 365 Loss 0.034 time 7.05\n",
      "Epoch 366 Loss 0.032 time 7.23\n",
      "Epoch 367 Loss 0.031 time 6.92\n",
      "Epoch 368 Loss 0.032 time 6.98\n",
      "Epoch 369 Loss 0.033 time 6.76\n",
      "Epoch 370 Loss 0.033 time 6.83\n",
      "Epoch 371 Loss 0.034 time 6.75\n",
      "Epoch 372 Loss 0.032 time 7.07\n",
      "Epoch 373 Loss 0.032 time 7.05\n",
      "Epoch 374 Loss 0.034 time 7.03\n",
      "Epoch 375 Loss 0.034 time 7.03\n",
      "Epoch 376 Loss 0.034 time 7.20\n",
      "Epoch 377 Loss 0.032 time 7.09\n",
      "Epoch 378 Loss 0.033 time 8.10\n",
      "Epoch 379 Loss 0.033 time 8.60\n",
      "Epoch 380 Loss 0.033 time 6.88\n",
      "Epoch 381 Loss 0.033 time 7.10\n",
      "Epoch 382 Loss 0.031 time 6.76\n",
      "Epoch 383 Loss 0.032 time 7.00\n",
      "Epoch 384 Loss 0.031 time 6.86\n",
      "Epoch 385 Loss 0.032 time 6.97\n",
      "Epoch 386 Loss 0.031 time 6.84\n",
      "Epoch 387 Loss 0.031 time 6.92\n",
      "Epoch 388 Loss 0.032 time 7.05\n",
      "Epoch 389 Loss 0.032 time 7.99\n",
      "Epoch 390 Loss 0.034 time 7.44\n",
      "Epoch 391 Loss 0.032 time 7.88\n",
      "Epoch 392 Loss 0.033 time 9.10\n",
      "Epoch 393 Loss 0.032 time 8.61\n",
      "Epoch 394 Loss 0.032 time 8.93\n",
      "Epoch 395 Loss 0.031 time 8.04\n",
      "Epoch 396 Loss 0.030 time 7.92\n",
      "Epoch 397 Loss 0.030 time 6.56\n",
      "Epoch 398 Loss 0.034 time 7.00\n",
      "Epoch 399 Loss 0.031 time 7.23\n",
      "Epoch 400 Loss 0.031 time 6.98\n",
      "Epoch 401 Loss 0.032 time 7.38\n",
      "Epoch 402 Loss 0.030 time 7.76\n",
      "Epoch 403 Loss 0.031 time 8.04\n",
      "Epoch 404 Loss 0.032 time 9.49\n",
      "Epoch 405 Loss 0.030 time 7.65\n",
      "Epoch 406 Loss 0.030 time 6.95\n",
      "Epoch 407 Loss 0.031 time 7.22\n",
      "Epoch 408 Loss 0.030 time 6.94\n",
      "Epoch 409 Loss 0.033 time 8.32\n",
      "Epoch 410 Loss 0.032 time 7.66\n",
      "Epoch 411 Loss 0.029 time 8.83\n",
      "Epoch 412 Loss 0.032 time 10.63\n",
      "Epoch 413 Loss 0.029 time 8.51\n",
      "Epoch 414 Loss 0.031 time 7.66\n",
      "Epoch 415 Loss 0.030 time 7.74\n",
      "Epoch 416 Loss 0.034 time 8.16\n",
      "Epoch 417 Loss 0.031 time 7.14\n",
      "Epoch 418 Loss 0.031 time 7.02\n",
      "Epoch 419 Loss 0.029 time 6.73\n",
      "Epoch 420 Loss 0.033 time 6.85\n",
      "Epoch 421 Loss 0.031 time 6.59\n",
      "Epoch 422 Loss 0.030 time 7.14\n",
      "Epoch 423 Loss 0.032 time 8.41\n",
      "Epoch 424 Loss 0.033 time 8.01\n",
      "Epoch 425 Loss 0.029 time 7.46\n",
      "Epoch 426 Loss 0.032 time 6.82\n",
      "Epoch 427 Loss 0.030 time 6.88\n",
      "Epoch 428 Loss 0.032 time 8.03\n",
      "Epoch 429 Loss 0.030 time 9.56\n",
      "Epoch 430 Loss 0.031 time 8.42\n",
      "Epoch 431 Loss 0.033 time 7.30\n",
      "Epoch 432 Loss 0.031 time 7.08\n",
      "Epoch 433 Loss 0.030 time 7.07\n",
      "Epoch 434 Loss 0.029 time 7.20\n",
      "Epoch 435 Loss 0.030 time 6.72\n",
      "Epoch 436 Loss 0.031 time 7.05\n",
      "Epoch 437 Loss 0.032 time 7.04\n",
      "Epoch 438 Loss 0.029 time 7.04\n",
      "Epoch 439 Loss 0.029 time 7.03\n",
      "Epoch 440 Loss 0.032 time 7.04\n",
      "Epoch 441 Loss 0.031 time 6.89\n",
      "Epoch 442 Loss 0.031 time 6.95\n",
      "Epoch 443 Loss 0.030 time 7.16\n",
      "Epoch 444 Loss 0.029 time 6.94\n",
      "Epoch 445 Loss 0.032 time 7.68\n",
      "Epoch 446 Loss 0.032 time 6.93\n",
      "Epoch 447 Loss 0.030 time 7.18\n",
      "Epoch 448 Loss 0.031 time 7.22\n",
      "Epoch 449 Loss 0.030 time 7.42\n",
      "Epoch 450 Loss 0.030 time 7.13\n",
      "Epoch 451 Loss 0.030 time 7.21\n",
      "Epoch 452 Loss 0.030 time 7.17\n",
      "Epoch 453 Loss 0.032 time 7.04\n",
      "Epoch 454 Loss 0.030 time 7.39\n",
      "Epoch 455 Loss 0.031 time 7.81\n",
      "Epoch 456 Loss 0.029 time 9.95\n",
      "Epoch 457 Loss 0.032 time 9.06\n",
      "Epoch 458 Loss 0.030 time 10.22\n",
      "Epoch 459 Loss 0.029 time 8.72\n",
      "Epoch 460 Loss 0.029 time 7.44\n",
      "Epoch 461 Loss 0.029 time 7.24\n",
      "Epoch 462 Loss 0.030 time 8.76\n",
      "Epoch 463 Loss 0.031 time 9.32\n",
      "Epoch 464 Loss 0.029 time 7.14\n",
      "Epoch 465 Loss 0.029 time 6.78\n",
      "Epoch 466 Loss 0.028 time 7.35\n",
      "Epoch 467 Loss 0.030 time 7.46\n",
      "Epoch 468 Loss 0.029 time 7.18\n",
      "Epoch 469 Loss 0.028 time 6.83\n",
      "Epoch 470 Loss 0.031 time 7.09\n",
      "Epoch 471 Loss 0.029 time 7.16\n",
      "Epoch 472 Loss 0.029 time 8.64\n",
      "Epoch 473 Loss 0.030 time 7.25\n",
      "Epoch 474 Loss 0.030 time 7.85\n",
      "Epoch 475 Loss 0.029 time 8.22\n",
      "Epoch 476 Loss 0.029 time 9.13\n",
      "Epoch 477 Loss 0.030 time 7.66\n",
      "Epoch 478 Loss 0.029 time 7.74\n",
      "Epoch 479 Loss 0.030 time 7.03\n",
      "Epoch 480 Loss 0.029 time 6.77\n",
      "Epoch 481 Loss 0.030 time 8.73\n",
      "Epoch 482 Loss 0.029 time 8.48\n",
      "Epoch 483 Loss 0.029 time 7.27\n",
      "Epoch 484 Loss 0.030 time 7.77\n",
      "Epoch 485 Loss 0.030 time 7.95\n",
      "Epoch 486 Loss 0.029 time 7.10\n",
      "Epoch 487 Loss 0.029 time 7.54\n",
      "Epoch 488 Loss 0.030 time 8.03\n",
      "Epoch 489 Loss 0.031 time 7.69\n",
      "Epoch 490 Loss 0.029 time 6.89\n",
      "Epoch 491 Loss 0.028 time 7.27\n",
      "Epoch 492 Loss 0.029 time 8.80\n",
      "Epoch 493 Loss 0.029 time 8.81\n",
      "Epoch 494 Loss 0.027 time 8.73\n",
      "Epoch 495 Loss 0.028 time 8.45\n",
      "Epoch 496 Loss 0.028 time 7.18\n",
      "Epoch 497 Loss 0.030 time 7.63\n",
      "Epoch 498 Loss 0.029 time 7.62\n",
      "Epoch 499 Loss 0.029 time 7.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseAsyncIOLoop._handle_events(14, 1)\n",
      "handle: <Handle BaseAsyncIOLoop._handle_events(14, 1)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 239, in dispatch_shell\n",
      "    sys.stdout.flush()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in flush\n",
      "    if self.pub_thread.thread.is_alive():\n",
      "AttributeError: 'NoneType' object has no attribute 'thread'\n"
     ]
    }
   ],
   "source": [
    "opt['model'] = 'torch'\n",
    "opt['out'] = 'delta_cpu_lstm'\n",
    "rnnSMAP.funLSTM.trainLSTM(opt)\n",
    "\n",
    "out = opt['out']\n",
    "rootOut = rnnSMAP.kPath['Out_L3_NA']\n",
    "syr = 2015\n",
    "eyr = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 'delta_cpu_lstm'\n",
    "testName = 'CONUSv16f1'\n",
    "rootDB = rnnSMAP.kPath['DB_L3_NA']\n",
    "rootOut = rnnSMAP.kPath['Out_L3_NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2017/SMAP_AM.csv 0.03252816200256348\n",
      "later\n",
      "reading /Users/rajdesai/Desktop/Hydro/output/L3_NA/delta_cpu_lstm/test_CONUSv16f1_2017_2017_ep500.csv\n"
     ]
    }
   ],
   "source": [
    "ds1 = rnnSMAP.classDB.DatasetPost(rootDB=rootDB, subsetName=testName, yrLst=[2017])# define dataset\n",
    "ds1.readData(var='SMAP_AM', field='SMAP')# read target\n",
    "print(\"HIHIHIHIHIHIHIHIHIH\")\n",
    "ds1.readPred(rootOut=rootOut, out=out, drMC=0, field='LSTM')# read prediction\n",
    "statErr1 = ds1.statCalError(predField='LSTM', targetField='SMAP')# calculate error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/SMAP_AM.csv 0.022329092025756836\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/SMAP_AM.csv 0.021058082580566406\n",
      "running test\n",
      "/Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/Subset/CONUSv16f1.csv\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/APCP_FORA.csv 0.014808177947998047\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/APCP_FORA.csv 0.015017986297607422\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/DLWRF_FORA.csv 0.015623092651367188\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/DLWRF_FORA.csv 0.015383005142211914\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/DSWRF_FORA.csv 0.014822244644165039\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/DSWRF_FORA.csv 0.015594959259033203\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/TMP_2_FORA.csv 0.018583059310913086\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/TMP_2_FORA.csv 0.03311586380004883\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/SPFH_2_FORA.csv 0.017208099365234375\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/SPFH_2_FORA.csv 0.022307634353637695\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/VGRD_10_FORA.csv 0.015154123306274414\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/VGRD_10_FORA.csv 0.016189098358154297\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2015/UGRD_10_FORA.csv 0.015059947967529297\n",
      "read /Users/rajdesai/Desktop/Hydro/data/Daily_L3_NA/CONUSv16f1/2016/UGRD_10_FORA.csv 0.016083955764770508\n",
      "saving /Users/rajdesai/Desktop/Hydro/output/L3_NA/delta_cpu_lstm/test_CONUSv16f1_2015_2016_ep500.csv\n",
      "reading /Users/rajdesai/Desktop/Hydro/output/L3_NA/delta_cpu_lstm/test_CONUSv16f1_2015_2016_ep500.csv\n"
     ]
    }
   ],
   "source": [
    "ds2 = rnnSMAP.classDB.DatasetPost(rootDB=rootDB, subsetName=testName, yrLst=[2015, 2016])\n",
    "ds2.readData(var='SMAP_AM', field='SMAP')\n",
    "ds2.readPred(rootOut=rootOut, out=out, drMC=0, field='LSTM')\n",
    "statErr2 = ds2.statCalError(predField='LSTM', targetField='SMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strE = 'RMSE'\n",
    "dataErr = [getattr(statErr1, strE), getattr(statErr2, strE)]\n",
    "fig = rnnSMAP.funPost.plotBox(dataErr, labelC=['train', 'test'], title='Temporal Test ' + strE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
